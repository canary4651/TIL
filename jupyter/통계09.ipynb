{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from statsmodels.formula.api import glm\n",
    "from statsmodels.genmod.families.family import Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnout = pandas.read_csv('burnout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>burnout</th>\n",
       "      <th>loc</th>\n",
       "      <th>cope</th>\n",
       "      <th>teaching</th>\n",
       "      <th>research</th>\n",
       "      <th>pastoral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Burnt Out</td>\n",
       "      <td>7.647059</td>\n",
       "      <td>9.160305</td>\n",
       "      <td>32.727273</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>31.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Burnt Out</td>\n",
       "      <td>6.470588</td>\n",
       "      <td>12.977099</td>\n",
       "      <td>52.727273</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>68.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Burnt Out</td>\n",
       "      <td>8.823529</td>\n",
       "      <td>9.160305</td>\n",
       "      <td>49.090909</td>\n",
       "      <td>60.416667</td>\n",
       "      <td>53.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Burnt Out</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>9.160305</td>\n",
       "      <td>52.727273</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Burnt Out</td>\n",
       "      <td>6.470588</td>\n",
       "      <td>19.083969</td>\n",
       "      <td>43.636364</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>40.740741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         burnout        loc       cope   teaching   research   pastoral\n",
       "0  Not Burnt Out   7.647059   9.160305  32.727273  87.500000  31.481481\n",
       "1  Not Burnt Out   6.470588  12.977099  52.727273  66.666667  68.518519\n",
       "2  Not Burnt Out   8.823529   9.160305  49.090909  60.416667  53.703704\n",
       "3  Not Burnt Out  20.000000   9.160305  52.727273  62.500000  50.000000\n",
       "4  Not Burnt Out   6.470588  19.083969  43.636364  79.166667  40.740741"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burnout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnout['y'] = burnout['burnout'].replace({'Burnt Out': 1, 'Not Burnt Out': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = glm('y ~ cope', burnout, family=Binomial()).fit()\n",
    "# glm : 일반화 선형 모형 (generalize) 더 적용하기 쉽게 바꿈 - faimly를 만들어줌 \n",
    "# y = ax+b에서 family를 줘서 변형을 해주는 거임 (bionomal - 로지스틱)\n",
    "# binomial로 faimly를 지정해주면, 로지스틱 선형 모형으로 바꿔줌 (cope를 가지고 y를 예측)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   467</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   465</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -199.52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 01 Oct 2019</td> <th>  Deviance:          </th> <td>  399.03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:34:32</td>     <th>  Pearson chi2:      </th>  <td>  575.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -3.3839</td> <td>    0.283</td> <td>  -11.943</td> <td> 0.000</td> <td>   -3.939</td> <td>   -2.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cope</th>      <td>    0.0862</td> <td>    0.009</td> <td>    9.519</td> <td> 0.000</td> <td>    0.068</td> <td>    0.104</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  467\n",
       "Model:                            GLM   Df Residuals:                      465\n",
       "Model Family:                Binomial   Df Model:                            1\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -199.52\n",
       "Date:                Tue, 01 Oct 2019   Deviance:                       399.03\n",
       "Time:                        10:34:32   Pearson chi2:                     575.\n",
       "No. Iterations:                     5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -3.3839      0.283    -11.943      0.000      -3.939      -2.829\n",
       "cope           0.0862      0.009      9.519      0.000       0.068       0.104\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()\n",
    "# 계수가 제일 중요 : cope -> 신뢰구간이 둘 다 ++ , cope의 값이 올라갈 수록 burn out 될 확률도 올라간다 \n",
    "# aic, bic 확인 ( 이 표에서 안 보여주니까 밑에서 수동으로 확인) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403.0328572766329"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2459.010247539404"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.bic\n",
    "# 왜 - 지..? 계산이 좀 이상,,, 선생님이 다시 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cope말고 teaching 변수 넣어보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = glm('y ~ teaching', burnout, family=Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   467</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   465</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -247.30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 01 Oct 2019</td> <th>  Deviance:          </th> <td>  494.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:36:12</td>     <th>  Pearson chi2:      </th>  <td>  457.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>4</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -3.9560</td> <td>    0.532</td> <td>   -7.439</td> <td> 0.000</td> <td>   -4.998</td> <td>   -2.914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>teaching</th>  <td>    0.0504</td> <td>    0.009</td> <td>    5.679</td> <td> 0.000</td> <td>    0.033</td> <td>    0.068</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  467\n",
       "Model:                            GLM   Df Residuals:                      465\n",
       "Model Family:                Binomial   Df Model:                            1\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -247.30\n",
       "Date:                Tue, 01 Oct 2019   Deviance:                       494.60\n",
       "Time:                        10:36:12   Pearson chi2:                     457.\n",
       "No. Iterations:                     4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -3.9560      0.532     -7.439      0.000      -4.998      -2.914\n",
       "teaching       0.0504      0.009      5.679      0.000       0.033       0.068\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()\n",
    "# teaching도 cope 처럼 하면 burn out 확률이 높아져감 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 둘 다 넣어보기 \n",
    "res = glm('y ~ teaching + cope', burnout, family=Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   467</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   464</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -196.55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 01 Oct 2019</td> <th>  Deviance:          </th> <td>  393.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:37:58</td>     <th>  Pearson chi2:      </th>  <td>  563.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -2.0771</td> <td>    0.592</td> <td>   -3.508</td> <td> 0.000</td> <td>   -3.238</td> <td>   -0.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>teaching</th>  <td>   -0.0323</td> <td>    0.013</td> <td>   -2.400</td> <td> 0.016</td> <td>   -0.059</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cope</th>      <td>    0.1050</td> <td>    0.012</td> <td>    8.443</td> <td> 0.000</td> <td>    0.081</td> <td>    0.129</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  467\n",
       "Model:                            GLM   Df Residuals:                      464\n",
       "Model Family:                Binomial   Df Model:                            2\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -196.55\n",
       "Date:                Tue, 01 Oct 2019   Deviance:                       393.09\n",
       "Time:                        10:37:58   Pearson chi2:                     563.\n",
       "No. Iterations:                     5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -2.0771      0.592     -3.508      0.000      -3.238      -0.917\n",
       "teaching      -0.0323      0.013     -2.400      0.016      -0.059      -0.006\n",
       "cope           0.1050      0.012      8.443      0.000       0.081       0.129\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()\n",
    "# cope가 같은 수준일 때 보면, teaching을 많이 한 사람이 오히려 burn out이 덜 됨 \n",
    "# 한 변수를 통제했을 때 다른 변수가 바뀌는 case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   467</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   463</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -177.25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 01 Oct 2019</td> <th>  Deviance:          </th> <td>  354.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:39:46</td>     <th>  Pearson chi2:      </th>  <td>  357.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>   -8.4114</td> <td>    1.359</td> <td>   -6.187</td> <td> 0.000</td> <td>  -11.076</td> <td>   -5.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>teaching</th>      <td>    0.0684</td> <td>    0.023</td> <td>    2.987</td> <td> 0.003</td> <td>    0.024</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cope</th>          <td>    0.3287</td> <td>    0.042</td> <td>    7.736</td> <td> 0.000</td> <td>    0.245</td> <td>    0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>teaching:cope</th> <td>   -0.0033</td> <td>    0.001</td> <td>   -5.802</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  467\n",
       "Model:                            GLM   Df Residuals:                      463\n",
       "Model Family:                Binomial   Df Model:                            3\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -177.25\n",
       "Date:                Tue, 01 Oct 2019   Deviance:                       354.51\n",
       "Time:                        10:39:46   Pearson chi2:                     357.\n",
       "No. Iterations:                     6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept        -8.4114      1.359     -6.187      0.000     -11.076      -5.747\n",
       "teaching          0.0684      0.023      2.987      0.003       0.024       0.113\n",
       "cope              0.3287      0.042      7.736      0.000       0.245       0.412\n",
       "teaching:cope    -0.0033      0.001     -5.802      0.000      -0.004      -0.002\n",
       "=================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# : (*)로 넣어볼 때 \n",
    "res = glm('y ~ teaching * cope', burnout, family=Binomial()).fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r 제곱이 없는 이유 ? - y는 확률이기 때문에 (연속 변수가 아니어서) r제곱 분산은 없음. \n",
    "# Deviance : Log-Likelihood * (-2) : 직접 쓸 일은 없고 지표 같은 내용을 계산할 때 씀 \n",
    "# 그냥 aic, bic 확인하면 됨. (0에 가까운 쪽이 좋다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.015454\n",
       "1      0.057103\n",
       "2      0.028438\n",
       "3      0.032525\n",
       "4      0.128978\n",
       "         ...   \n",
       "462    0.694301\n",
       "463    0.933334\n",
       "464    0.506838\n",
       "465    0.772203\n",
       "466    0.342818\n",
       "Length: 467, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = res.predict(burnout)\n",
    "# predict 함수 (독립변수에 해당되는 데이터를 넣어주면 됨 - 알아서 y의 확률을 알려줌 ) - 로지스틱 말고 선형 모형도 가능함\n",
    "# 원칙적으로는 새 데이터(b아예 다른 테이블에서 조사해보지 않은 독립변수들을 넣어줘야 함)\n",
    "# 로지스틱 회귀분석(glm) -> res(계수) -> res.predict : 새 데이터(y가 없으니까 예측) / 원래 데이터(실제 y하고 예측을 비교해서 채점)\n",
    "prob \n",
    "# 0.015 -> 1.5% (brun out 될 확률)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = numpy.where(prob > .5, 1, 0) #기준점 50%, 높으면 1, 낮으면 0 \n",
    "# where 함수 (어디서 자를거냐)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 혼돈행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# 혼돈행렬 : 말 그래도 혼돈..! 4가지 경우 \n",
    "# burn out 안 된 경우 -> 된 경우 (혹은 그 반대)\n",
    "# 물론 aic, bic가 그 모델이 맞았는 지 판단해주지만, 혼돈행렬까지 보면 더 확실히 알 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[311,  37],\n",
       "       [ 58,  61]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = burnout['y']\n",
    "confusion_matrix(true, pred)\n",
    "# 세로가 예측, 가로가 실제 (표)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                        예측\n",
    "                      Not Burnt Out     Burnt Out\n",
    "실제  Not Burnt Out    311(ture-nagative)   27(false positive) \n",
    "       Burnt Out      72(false-nagative)   47(true positive)\n",
    "        \n",
    "정확도 = tn+tp/전체합(tn+fn+fp+tp) = 378/467 \n",
    "\n",
    "다른 확률들도 구할 수 있음 -> 내가 positive 예측한 게 얼마나 맞았냐(정밀도) tp/tp+fp : 예측(1)\n",
    "                     -> 실제 내가 문제가 있다고 예측한 게 얼마나 맞았냐(재현도) tp/fn+tp : 실제(1)\n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확도, 정밀도, 재현도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7965738758029979"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6224489795918368"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(true, pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5126050420168067"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(true, pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC 곡선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(true, prob, pos_label=1) #prob : 확률(기준) \n",
    "# 정밀도, 재현도, 기준값 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.990357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.990357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.959496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.949422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.920528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.916035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.092437</td>\n",
       "      <td>0.907775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.894815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.867725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.126050</td>\n",
       "      <td>0.865184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.126050</td>\n",
       "      <td>0.856464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.151261</td>\n",
       "      <td>0.844417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.151261</td>\n",
       "      <td>0.834141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.809298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.804213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>0.795034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.193277</td>\n",
       "      <td>0.794254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.193277</td>\n",
       "      <td>0.788633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.201681</td>\n",
       "      <td>0.784353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.201681</td>\n",
       "      <td>0.778998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.210084</td>\n",
       "      <td>0.772203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.210084</td>\n",
       "      <td>0.768467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.743385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.742122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.048851</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.694408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.260504</td>\n",
       "      <td>0.694301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.268908</td>\n",
       "      <td>0.689213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.686455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.319328</td>\n",
       "      <td>0.678996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.054598</td>\n",
       "      <td>0.336134</td>\n",
       "      <td>0.674637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.767241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.772989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.787356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.793103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.798851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.804598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.810345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.816092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.821839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.827586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.836207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.847701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.856322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.867816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.876437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.882184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.887931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.896552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.902299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.908046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.913793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.919540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.925287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.936782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.945402</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.948276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.959770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.977011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fpr       tpr  threshold\n",
       "0    0.000000  0.000000   1.990357\n",
       "1    0.000000  0.008403   0.990357\n",
       "2    0.000000  0.033613   0.959496\n",
       "3    0.002874  0.033613   0.949422\n",
       "4    0.002874  0.075630   0.920528\n",
       "..        ...       ...        ...\n",
       "206  0.948276  1.000000   0.019735\n",
       "207  0.959770  1.000000   0.018234\n",
       "208  0.977011  1.000000   0.014572\n",
       "209  0.982759  1.000000   0.014435\n",
       "210  1.000000  1.000000   0.006955\n",
       "\n",
       "[211 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame({'fpr':fpr, 'tpr':tpr, 'threshold':threshold})\n",
    "# 1.99 값? -> 별 의미는 없음. 확률은 0-1사이임. 확률 100%를 넘길 순 없으니 그냥 1이랑 같은 값."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1273f4490>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.lineplot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8789843523616343"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr, tpr)\n",
    "# auc (arial under curve) : 곡선 아래 모양이 어떻게 되냐 (역 ㄱ자면일수록 좋음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pandas.read_csv('wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>MalicAcid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>AlcalinityOfAsh</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>TotalPhenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>NonflavanoidPhenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  MalicAcid   Ash  AlcalinityOfAsh  Magnesium  TotalPhenols  \\\n",
       "0      1    14.23       1.71  2.43             15.6        127          2.80   \n",
       "1      1    13.20       1.78  2.14             11.2        100          2.65   \n",
       "2      1    13.16       2.36  2.67             18.6        101          2.80   \n",
       "3      1    14.37       1.95  2.50             16.8        113          3.85   \n",
       "4      1    13.24       2.59  2.87             21.0        118          2.80   \n",
       "\n",
       "   Flavanoids  NonflavanoidPhenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "0        3.06                 0.28             2.29             5.64  1.04   \n",
       "1        2.76                 0.26             1.28             4.38  1.05   \n",
       "2        3.24                 0.30             2.81             5.68  1.03   \n",
       "3        3.49                 0.24             2.18             7.80  0.86   \n",
       "4        2.69                 0.39             1.82             4.32  1.04   \n",
       "\n",
       "     OD  Proline  \n",
       "0  3.92     1065  \n",
       "1  3.40     1050  \n",
       "2  3.17     1185  \n",
       "3  3.45     1480  \n",
       "4  2.93      735  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wine.iloc[:, 1:] # iloc(번호로 위치지정) [:, 1:] 첫번째는 모든 행, 두번째는 1열부터 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>MalicAcid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>AlcalinityOfAsh</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>TotalPhenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>NonflavanoidPhenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  MalicAcid   Ash  AlcalinityOfAsh  Magnesium  TotalPhenols  \\\n",
       "0    14.23       1.71  2.43             15.6        127          2.80   \n",
       "1    13.20       1.78  2.14             11.2        100          2.65   \n",
       "2    13.16       2.36  2.67             18.6        101          2.80   \n",
       "3    14.37       1.95  2.50             16.8        113          3.85   \n",
       "4    13.24       2.59  2.87             21.0        118          2.80   \n",
       "\n",
       "   Flavanoids  NonflavanoidPhenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "0        3.06                 0.28             2.29             5.64  1.04   \n",
       "1        2.76                 0.26             1.28             4.38  1.05   \n",
       "2        3.24                 0.30             2.81             5.68  1.03   \n",
       "3        3.49                 0.24             2.18             7.80  0.86   \n",
       "4        2.69                 0.39             1.82             4.32  1.04   \n",
       "\n",
       "     OD  Proline  \n",
       "0  3.92     1065  \n",
       "1  3.40     1050  \n",
       "2  3.17     1185  \n",
       "3  3.45     1480  \n",
       "4  2.93      735  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수들 수치가 다 다르기 때문에 일정한 범위로 맞춰줘야함 (크기를 동일하게 scaling)\n",
    "- 1) Min-Max Scaling : 최소값은 0, 최대값은 1이 되도록 조정 (굉장히 큰 극단치가 존재할 때, 고르게 분포하지 않고 중간이 비어버림)\n",
    "- 2) 표준화(Standardization): 모든 값에서 평균을 빼고, 표준편차로 나눠주는 것 (더 자주 쓰는 방법)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scale.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.518613</td>\n",
       "      <td>-0.562250</td>\n",
       "      <td>0.232053</td>\n",
       "      <td>-1.169593</td>\n",
       "      <td>1.913905</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>1.034819</td>\n",
       "      <td>-0.659563</td>\n",
       "      <td>1.224884</td>\n",
       "      <td>0.251717</td>\n",
       "      <td>0.362177</td>\n",
       "      <td>1.847920</td>\n",
       "      <td>1.013009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.246290</td>\n",
       "      <td>-0.499413</td>\n",
       "      <td>-0.827996</td>\n",
       "      <td>-2.490847</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>0.568648</td>\n",
       "      <td>0.733629</td>\n",
       "      <td>-0.820719</td>\n",
       "      <td>-0.544721</td>\n",
       "      <td>-0.293321</td>\n",
       "      <td>0.406051</td>\n",
       "      <td>1.113449</td>\n",
       "      <td>0.965242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196879</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>1.109334</td>\n",
       "      <td>-0.268738</td>\n",
       "      <td>0.088358</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>1.215533</td>\n",
       "      <td>-0.498407</td>\n",
       "      <td>2.135968</td>\n",
       "      <td>0.269020</td>\n",
       "      <td>0.318304</td>\n",
       "      <td>0.788587</td>\n",
       "      <td>1.395148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.691550</td>\n",
       "      <td>-0.346811</td>\n",
       "      <td>0.487926</td>\n",
       "      <td>-0.809251</td>\n",
       "      <td>0.930918</td>\n",
       "      <td>2.491446</td>\n",
       "      <td>1.466525</td>\n",
       "      <td>-0.981875</td>\n",
       "      <td>1.032155</td>\n",
       "      <td>1.186068</td>\n",
       "      <td>-0.427544</td>\n",
       "      <td>1.184071</td>\n",
       "      <td>2.334574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295700</td>\n",
       "      <td>0.227694</td>\n",
       "      <td>1.840403</td>\n",
       "      <td>0.451946</td>\n",
       "      <td>1.281985</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>0.663351</td>\n",
       "      <td>0.226796</td>\n",
       "      <td>0.401404</td>\n",
       "      <td>-0.319276</td>\n",
       "      <td>0.362177</td>\n",
       "      <td>0.449601</td>\n",
       "      <td>-0.037874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.518613 -0.562250  0.232053 -1.169593  1.913905  0.808997  1.034819   \n",
       "1  0.246290 -0.499413 -0.827996 -2.490847  0.018145  0.568648  0.733629   \n",
       "2  0.196879  0.021231  1.109334 -0.268738  0.088358  0.808997  1.215533   \n",
       "3  1.691550 -0.346811  0.487926 -0.809251  0.930918  2.491446  1.466525   \n",
       "4  0.295700  0.227694  1.840403  0.451946  1.281985  0.808997  0.663351   \n",
       "\n",
       "          7         8         9        10        11        12  \n",
       "0 -0.659563  1.224884  0.251717  0.362177  1.847920  1.013009  \n",
       "1 -0.820719 -0.544721 -0.293321  0.406051  1.113449  0.965242  \n",
       "2 -0.498407  2.135968  0.269020  0.318304  0.788587  1.395148  \n",
       "3 -0.981875  1.032155  1.186068 -0.427544  1.184071  2.334574  \n",
       "4  0.226796  0.401404 -0.319276  0.362177  0.449601 -0.037874  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(x).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3)\n",
    "# 데이터를 3개로 묶어서 각각 평균점을 찾음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['Class'].values\n",
    "# 3 집단 존재 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.predict(x)\n",
    "# 번호는 알아서 붙여줌. (원래 class에 존재하는 종류랑 대충 비슷하게 나옴)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AffinityPropagation(preference=-200)\n",
    "# preference : ap는 서로 비슷하면 대표를 선출하는 데, 그럼 얼마나 서로 비슷하냐! 를 조정해주는 게 바로 preference다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AffinityPropagation(affinity='euclidean', convergence_iter=15, copy=True,\n",
       "                    damping=0.5, max_iter=200, preference=-200, verbose=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 2, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MeanShift(bandwidth=3)\n",
    "# 어떤 점에서 거리가 3이내면 찾아서 평균을 낸다. 마지막에 평균에서 멈추는 점이 같은 애들끼리 군집 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanShift(bandwidth=3, bin_seeding=False, cluster_all=True, min_bin_freq=1,\n",
       "          n_jobs=None, seeds=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       9, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 8, 4, 4, 4, 0, 0, 0, 0, 4, 7, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.predict(x)\n",
    "# 결과가 이상하게 나옴 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SpectralClustering(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2,\n",
       "       2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.fit_predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = AgglomerativeClustering(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 0, 0, 0, 2,\n",
       "       2, 0, 1, 0, 1, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.fit_predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DBSCAN(eps=3, min_samples=5) # 거리, 개수 -> 주변 거리 3이내에 비슷한 값이 5개가 있어야함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0, -1,  0,  0,  0, -1,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, -1,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0, -1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.fit_predict(x)\n",
    "# -1 : 주변에 비슷한 군집 이 없는 데이터값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.3'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_km = km.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ap = ap.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3891879777181648"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_score(x, labels_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4523177938566059"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_score(x, labels_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2848589191898987"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(x, labels_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2511804643887535"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(x, labels_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
