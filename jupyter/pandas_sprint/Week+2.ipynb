{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-data-analysis/resources/0dhYG) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Series Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas의 Series란 뭘까요? 판다스의 구성요소들이 궁금하다면 '?'를 붙여 설명을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.Series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series는 1차원 배열 형식의 자료구조입니다. Series가 가지는 인덱스 라벨 값은 꼭 unique한 값일 필요는 없지만 hashable한 값이어야한다고 하는데요. 찾아보니 hash에 관한 복잡한 내용이 나오는데 골자는 중간에 값이 바뀌지 않아야한다는 것 같습니다.\n",
    "\n",
    "</br>\\\n",
    "</br>\\\n",
    "</br>\n",
    "\n",
    "Seires의 값으로는 문자, 숫자, None, 등이 담길 수 있습니다.\n",
    "인덱스 값을 특별히 지정하지 않을 경우 pandas는 자동으로 인덱스를 생성하여 할당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Tiger\n",
       "1     Bear\n",
       "2    Moose\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals = ['Tiger', 'Bear', 'Moose']\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [1, 2, 3]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Tiger\n",
       "1     Bear\n",
       "2     None\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals = ['Tiger', 'Bear', None]\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`int`와 `None` 값이 섞여 있을 경우 Series에서 `int` 형식이 자동으로 `float` 형식으로 변환되고 `None` 값은 `NaN`으로 표시됩니다. NaN은 Not A Number의 줄임말 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [1, 2, None]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\\\n",
    "`NaN`과 `None`은 다른 값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.nan == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\\\n",
    "</br>\n",
    "\n",
    "이번에는 인덱스가 설정된 시리즈를 만들어보겠습니다.\n",
    "1. 딕셔너리 자료형을 이용해 만드는 방법."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Archery           Bhutan\n",
       "Golf            Scotland\n",
       "Sumo               Japan\n",
       "Taekwondo    South Korea\n",
       "dtype: object"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Archery', 'Golf', 'Sumo', 'Taekwondo'], dtype='object')"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\\\n",
    "</br>\n",
    "\n",
    "\n",
    "2. 리스트 자료형을 이용하여 만드는 방법."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "India      Tiger\n",
       "America     Bear\n",
       "Canada     Moose\n",
       "dtype: object"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['Tiger', 'Bear', 'Moose'], index=['India', 'America', 'Canada'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딕셔너리 자료를 가져와서 인덱스를 다시 설정해주면,\n",
    "\n",
    "마지막에 설정한 index key(['Golf', 'Sumo', 'Hockey']) 값을 딕셔너리에서 찾아 value 값에 해당하는 값을 가져오고,\n",
    "\n",
    "딕셔너리에 없는 key를 인덱스로 설정할 경우 기본값인 None이 value로 할당되어 NaN 값으로 Series에 표현됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Golf      Scotland\n",
       "Sumo         Japan\n",
       "Hockey         NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports, index=['Golf', 'Sumo', 'Hockey'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "# Querying a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series에서 값을 불러오는 방법을 알아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Archery           Bhutan\n",
       "Golf            Scotland\n",
       "Sumo               Japan\n",
       "Taekwondo    South Korea\n",
       "dtype: object"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc` 속성과 `loc` 속성을 이용하면 각각의 행에 접근할 수 있습니다.\n",
    "\n",
    "index position로 위치를 검색하기 위해서는 `iloc` 속성으로 접근해야 하며, index label로 위치를 검색하기 위해서는 `loc` 속성으로 접근해야 합니다.\n",
    "\n",
    "`iloc`과 `loc`은 함수가 아니라 속성이므로 ()가 아니라 []로 참조합니다. column을 참조하는 형식과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'South Korea'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scotland'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loc['Golf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas는 똑똑하므로 `iloc`과 `loc`을 명시적으로 설정하지 않아도 `Series` 뒤에 []가 있으면 알아서 `iloc`또는 `loc`으로 우리가 보고 싶은 값을 찾아다주지만, 우리는 더 똑똑하니까 굳이 헷갈리지 않도록 명시적으로 사용해주는 것이 좋겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'South Korea'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scotland'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['Golf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "왜 생략하면 안되는지 알아보죠.\n",
    "\n",
    "Pandas가 위의 경우처럼 똑똑한 건 가끔 운이 좋을 때 뿐이라는 걸 알게되실겁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = {1: 'Bhutan',\n",
    "          100: 'Scotland',\n",
    "          101: 'Japan',\n",
    "          102: 'South Korea'}\n",
    "s = pd.Series(sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-283-d33d9d3f79a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#이건 작동하지 않습니다. s.iloc[0]을 기대하셨겠지만, 기대와는 다르게 에러를 뿜습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4721\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4722\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4723\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4724\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4725\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#이건 작동하지 않습니다. s.iloc[0]을 기대하셨겠지만, 기대와는 다르게 에러를 뿜습니다.\n",
    "s[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "이게 무슨일인지 아시겠나요? `loc`, 또는 `iloc`을 생략하면 우리의 뜻대로 값을 가져오지 못할 수 도 있다는 소리랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc`은 `list`의 인덱스 값을 받아오는 것처럼 생각하시면 좋을 것 같습니다. `loc`은 딕셔너리의 `key`를 받아오는 걸로 생각하면 편하겠네요.\n",
    "\n",
    "그래서 <결론>은 어지간하면 `iloc`은 쓸일 없다 치고 `loc`으로 index 값을 찾아본다고 생각하면 몸과 마음이 편할 듯 합니다.\n",
    "\n",
    "\n",
    "<br>\\\n",
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "이제 Series의 특징들을 알아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([100.00, 120.00, 101.00, 3.00])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series 속의 값들을 모두 더하고 싶다면 `for`문으로 모든 값을 하나씩 가져와 값을 더해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for item in s:\n",
    "    total+=item\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 numpy의 `sum()` 함수를 사용하면 좀 더 빠르게 연산을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "total = np.sum(s)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this creates a big series of random numbers\n",
    "s = pd.Series(np.random.randint(0,1000,10000))\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%%timeit`라는 기능을 사용하면 평균적인 실행 시간을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "summary = 0\n",
    "for item in s:\n",
    "    summary+=item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "summary = np.sum(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "또 다른 예시입니다. 모든 값에 +2를 하고 싶다면 다음과 같이 할 수 있습니다. broadcasting이라고 하는 방법이래요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s+=2 #adds two to each item in s using broadcasting\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`for`문으로도 물론 할 수 있죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, value in s.iteritems():\n",
    "    s.set_value(label, value+2)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "s = pd.Series(np.random.randint(0,100,1000))\n",
    "for label, value in s.iteritems():\n",
    "    s.loc[label]= value+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "s = pd.Series(np.random.randint(0,100,1000))\n",
    "s+=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결론은 pandas의 Series에는 for문으로 처리하는 것보다 나은 방법들이 많이 내장되어있다는 것. `for` 문으로 뭔가 처리해야할 것 같으면 그게 최선인지 한번만 더 생각해보세요. \n",
    "\n",
    "정확한 기술적인 내용은 vectorization이란 키워드로 한번 찾아보세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\n",
    "\n",
    "\n",
    "`loc`을 사용하여 새로운 index lable과 value를 가진 행을 추가할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3])\n",
    "s.loc['Animal'] = 'Bears'\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\n",
    "\n",
    "지금까지는 index label이 unique한 경우만 봤습니다. 그렇지 않은 경우도 한번 보죠.\n",
    "\n",
    "딕셔너리, 리스트를 사용하여 각각 시리즈 두개를 만들겠습니다.\n",
    "\n",
    "그리고 append를 사용하여 all_countries라는 시리즈로 두 시리즈를 합쳐보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sports = pd.Series({'Archery': 'Bhutan',\n",
    "                             'Golf': 'Scotland',\n",
    "                             'Sumo': 'Japan',\n",
    "                             'Taekwondo': 'South Korea'})\n",
    "cricket_loving_countries = pd.Series(['Australia',\n",
    "                                      'Barbados',\n",
    "                                      'Pakistan',\n",
    "                                      'England'], \n",
    "                                   index=['Cricket',\n",
    "                                          'Cricket',\n",
    "                                          'Cricket',\n",
    "                                          'Cricket'])\n",
    "all_countries = original_sports.append(cricket_loving_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_loving_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 수많은 Cricket들에게도 한꺼번에 `loc` 속성을 통해 접근할 수 있습니다!\n",
    "개멋졍!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries.loc['Cricket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "# The DataFrame Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 이제 DataFrame 을 구경해봅시다.\n",
    "\n",
    "각각의 개별 값들이 모여 Series라는 형태를 만드는 것 처럼,\n",
    "\n",
    "이번에는 각각의 Series 들이 모여 DataFrame이라는 형태를 만듭니다.\n",
    "\n",
    "Series에서는 하나의 인덱스에 한 종류의 값만 존재했으므로 행을 구분하는 `loc`과 `iloc`이라는 속성만 다뤘습니다.\n",
    "\n",
    "그러나 DataFrame에서는 하나의 인덱스에 여러 종류의 값들이 딸려오기 때문에 그 인덱스가 가진 값들 중에서 어떤 종류의 값을 가져올 것인지 까지 알아야 합니다. 이 값이 어떤 종류의 값인지 표시해주는 속성을 `column`이라고 합니다. 엑셀에서 많이 본 개념이니까 따로 설명하지 않곘습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "purchase_1 = pd.Series({'Name': 'Chris',\n",
    "                        'Item Purchased': 'Dog Food',\n",
    "                        'Cost': 22.50})\n",
    "purchase_2 = pd.Series({'Name': 'Kevyn',\n",
    "                        'Item Purchased': 'Kitty Litter',\n",
    "                        'Cost': 2.50})\n",
    "purchase_3 = pd.Series({'Name': 'Vinod',\n",
    "                        'Item Purchased': 'Bird Seed',\n",
    "                        'Cost': 5.00})\n",
    "df = pd.DataFrame([purchase_1, purchase_2, purchase_3], index=['Store 1', 'Store 1', 'Store 2'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame에서도 여전히 `loc`은 사용할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `loc`을 통해 참조되는 값은 한 종류의 값이 아니라 여러 종류의 값들이 들어있는 Series들 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.loc['Store 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물론 해당하는 인덱스 값이 여러개 있다면 여러 행의 정보가 함께 참조됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc`은 location의 줄임말 입니다. 데이터의 위치를 지정해서 값을 가져올 수 있다는 소리겠죠. DataFrame에서는 `loc`을 사용해서 index 뿐만 아니라 column까지 설정할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 1', 'Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "그럼 column은 어떻게 참조할까요. loc을 사용해서 column을 참조하려면 이렇게 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose index and columns.라고 합니다. index와 column의 위치를 바꿉니다.\n",
    "df.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.loc['Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas 개발자들은 바보가 아닙니다. 위와 같은 복잡한 방법말고,\n",
    "\n",
    "column은 무조건 string 형식으로 되어있는 컬럼 명이 기본이므로 아래와 같이 간단하게 접근하게 만들었습니다.(번호고 뭐고 그냥 일단 이름.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 이제 아래처럼 값에 접근할 수 있습니다.\n",
    "\n",
    "이렇게 생긴 접근법을 chaining operation이라고 합니다. 결과가 나온 값에서 다시 뭔가를 참조하고 싶을 때 괄호를 덧붙여 계속해서 연산을 시켜 결과값을 볼 수 있는 방식이죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 1']['Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.loc['Store 1', 'Cost']`의 결과와 결과 자체는 같습니다.\n",
    "다만 한번에 접근하느냐, 차례로 접근하느냐가 다른 듯 합니다.\n",
    "- 6 - 2 + 2 = 6\n",
    "- 6 - 2 = 4, 4 + 2 = 6 ____ # chaining operation\n",
    "\n",
    "이정도의 차이? 당연히 후자가 더 느리겠죠. 데이터 자체를 copy하거나 select 할때는 별 문제가 없겠습니다만 데이터 값을 연산한다거나 하면 오류의 원인이 될 수 있다고도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "`loc` 속성으로 slicing을 할 수도 있습니다.\n",
    "\n",
    "`loc[첫번째, 두번쨰]`\n",
    "- 첫번째에는 슬라이스 해오고 싶은 행들의 범위를 가져옵니다.\n",
    "- 두번째에는 그 행들에서 가져오고 싶은 colum들의 이름을 씁니다. 기본은 모두 다 가져오는 겁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['Name', 'Cost']]\n",
    "# [:] 전체 행들을 가져와서 \n",
    "# ['Name', 'Cost'] 컬럼에 있는 값들을 표시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:'Store 1', ['Name']]\n",
    "# 'Store 1' 인덱스까지의 행들을 가져와서 \n",
    "# ['Name'] 컬럼에 있는 값들을 표시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:'Store 2', ['Name']]\n",
    "# 'Store 2' 인덱스까지의 행들을 가져와서 \n",
    "# ['Name'] 컬럼에 있는 값들을 표시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:2, :2]\n",
    "# iloc을 이용하면 인덱스 값으로 슬라이싱을 할 수도 있습니다.\n",
    "# colum은 iloc에서는 colum을 참조시킬 때도 숫자로 읽어올 위치를 지정해줄 수 있습니다.\n",
    "# 위의 예시는 2행, 2열까지의 값을 가져온 예시입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "열심히 참조해봤으니 이제 없애는 걸 해봅시다.\n",
    "\n",
    "'Store 1'이 망했다고 합시다. 데이터 관리할 필요가 없어졌습니다.\n",
    "\n",
    "'Store 1'의 데이터들만 없앤 데이터베이스를 얻고 싶습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Store 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 데이터는 어떨까요?\n",
    "\n",
    "pandas에서 `drop()`을 하면 기본적으로 원본 데이터를 바꿔주지는 않습니다. drop()하고 싶은 데이터가 사라진 복사본을 우리에게 던져주는 겁니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명시적으로 보자면 아래의 경우와 똑같은 프로세스라고 생각하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = df.copy()\n",
    "copy_df = copy_df.drop('Store 1')\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물론 pandas 개발자들은 똑똑하니까 우리가 원본 데이터를 변경하고 싶을거라는 것을 알고 있었습니다.\n",
    "\n",
    "`drop()` 함수의 옵션을 보면 원본데이터를 변형하는 `inplace`라는 옵션이 따로 있습니다. 다만 기본값이 `False`로 되어있으니 기본적으로는 원본을 변경하지 않고 복사본을 변경하여 출력하는 겁니다.\n",
    "\n",
    "`dopy_df.drop('Store 1', inplace=True)` 이렇게 하면 원본에서 'Store 1'이 `drop()`됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df.drop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`drop()`의 옵셥 중 `axis`를 1로 하면 인덱스 값이 아니라 column 값을 drop할 수 있습니다. 마찬가지로 drop()된 사본을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "column을 제거하는 방법은 한 가지가 더 있습니다.\n",
    "\n",
    "`del` 옵션을 사용하면 원본에서 column이 제거되고 결과값은 반환되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del copy_df['Name']\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새로운 column을 추가할 때는 아래와 같이 간단하게 추가할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['details'] = ['단골', '초등학생', '새박사님']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\\\n",
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "# Dataframe Indexing and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = df['Cost']\n",
    "costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 프레임에서 뭔가 연산을 하거나 가공을 할 때에는 이 연산이 원본 데이터를 변경시키는지 아는 것이 굉장히 중요합니다.\n",
    "\n",
    "Broadcasting이 또 나왔습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs+=2\n",
    "costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting을 하게되면 원본 데이터가 바뀝니다.\n",
    "\n",
    "내가 쓰는 연산이 원본 데이터에 영향을 미쳤는지는 안 미쳤는지는 알고있어야겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "csv 파일을 가져와서 DataFrame으로 만드는 방법을 알아봅시다.\n",
    "\n",
    "olympics.csv 파일은 아래와 같이 생긴 텍스트 파일입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat olympics.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "똑똑한 pandas 개발자들은 엑셀, csv 등등의 파일을 바로 데이터 프레임으로 만들어주는 기능을 넣어두었습니다.\n",
    "\n",
    "olympics.csv를 가져와서 DataFrame으로 만들어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('olympics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "근데 뭔가 이상합니다.\n",
    "\n",
    "우리가 흔히 보는 엑셀 파일들도 까보면 값들만 들어있는 게 아니라 행과 열이 이미 만들어져 있는 경우가 많죠. 때문에 그냥 `read_csv()`를 하게되면 우리가 생각한 대로 안들어갈 경우가 많습니다. 그럴 때는 어떻게 해야할까요?\n",
    "\n",
    "csv 파일 내에 이미 행과 열이 구분되어있는 경우라면 `read_csv()`에 옵션을 주어 해당 행과 열을 pandas가 알아들을 수 있는 index와 column으로 설정해주는 과정이 필요합니다.\n",
    "\n",
    "index_col은 인덱스로 삼을 컬럼의 위치를 지정합니다.\n",
    "\n",
    "skiptows을 이용해서는 불필요한 행들을 날려버리고 column으로 사용할 첫번째 행을 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('olympics.csv', index_col = 0, skiprows=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "셋팅된 column들은 columns로 불러와 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BIRTHS2010', 'BIRTHS2011', 'BIRTHS2012', 'BIRTHS2013', 'BIRTHS2014',\n",
       "       'BIRTHS2015', 'POPESTIMATE2010', 'POPESTIMATE2011', 'POPESTIMATE2012',\n",
       "       'POPESTIMATE2013', 'POPESTIMATE2014', 'POPESTIMATE2015'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column 이름들이 깨졌나보네요. 이상하니까 하나씩 바꿔주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>BIRTHS2010</th>\n",
       "      <th>BIRTHS2011</th>\n",
       "      <th>BIRTHS2012</th>\n",
       "      <th>BIRTHS2013</th>\n",
       "      <th>BIRTHS2014</th>\n",
       "      <th>BIRTHS2015</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>POPESTIMATE2011</th>\n",
       "      <th>POPESTIMATE2012</th>\n",
       "      <th>POPESTIMATE2013</th>\n",
       "      <th>POPESTIMATE2014</th>\n",
       "      <th>POPESTIMATE2015</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n",
       "      <th>Autauga County</th>\n",
       "      <td>151</td>\n",
       "      <td>636</td>\n",
       "      <td>615</td>\n",
       "      <td>574</td>\n",
       "      <td>623</td>\n",
       "      <td>600</td>\n",
       "      <td>54660</td>\n",
       "      <td>55253</td>\n",
       "      <td>55175</td>\n",
       "      <td>55038</td>\n",
       "      <td>55290</td>\n",
       "      <td>55347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baldwin County</th>\n",
       "      <td>517</td>\n",
       "      <td>2187</td>\n",
       "      <td>2092</td>\n",
       "      <td>2160</td>\n",
       "      <td>2186</td>\n",
       "      <td>2240</td>\n",
       "      <td>183193</td>\n",
       "      <td>186659</td>\n",
       "      <td>190396</td>\n",
       "      <td>195126</td>\n",
       "      <td>199713</td>\n",
       "      <td>203709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbour County</th>\n",
       "      <td>70</td>\n",
       "      <td>335</td>\n",
       "      <td>300</td>\n",
       "      <td>283</td>\n",
       "      <td>260</td>\n",
       "      <td>269</td>\n",
       "      <td>27341</td>\n",
       "      <td>27226</td>\n",
       "      <td>27159</td>\n",
       "      <td>26973</td>\n",
       "      <td>26815</td>\n",
       "      <td>26489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bibb County</th>\n",
       "      <td>44</td>\n",
       "      <td>266</td>\n",
       "      <td>245</td>\n",
       "      <td>259</td>\n",
       "      <td>247</td>\n",
       "      <td>253</td>\n",
       "      <td>22861</td>\n",
       "      <td>22733</td>\n",
       "      <td>22642</td>\n",
       "      <td>22512</td>\n",
       "      <td>22549</td>\n",
       "      <td>22583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blount County</th>\n",
       "      <td>183</td>\n",
       "      <td>744</td>\n",
       "      <td>710</td>\n",
       "      <td>646</td>\n",
       "      <td>618</td>\n",
       "      <td>603</td>\n",
       "      <td>57373</td>\n",
       "      <td>57711</td>\n",
       "      <td>57776</td>\n",
       "      <td>57734</td>\n",
       "      <td>57658</td>\n",
       "      <td>57673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        BIRTHS2010  BIRTHS2011  BIRTHS2012  BIRTHS2013  \\\n",
       "STNAME  CTYNAME                                                          \n",
       "Alabama Autauga County         151         636         615         574   \n",
       "        Baldwin County         517        2187        2092        2160   \n",
       "        Barbour County          70         335         300         283   \n",
       "        Bibb County             44         266         245         259   \n",
       "        Blount County          183         744         710         646   \n",
       "\n",
       "                        BIRTHS2014  BIRTHS2015  POPESTIMATE2010  \\\n",
       "STNAME  CTYNAME                                                   \n",
       "Alabama Autauga County         623         600            54660   \n",
       "        Baldwin County        2186        2240           183193   \n",
       "        Barbour County         260         269            27341   \n",
       "        Bibb County            247         253            22861   \n",
       "        Blount County          618         603            57373   \n",
       "\n",
       "                        POPESTIMATE2011  POPESTIMATE2012  POPESTIMATE2013  \\\n",
       "STNAME  CTYNAME                                                             \n",
       "Alabama Autauga County            55253            55175            55038   \n",
       "        Baldwin County           186659           190396           195126   \n",
       "        Barbour County            27226            27159            26973   \n",
       "        Bibb County               22733            22642            22512   \n",
       "        Blount County             57711            57776            57734   \n",
       "\n",
       "                        POPESTIMATE2014  POPESTIMATE2015  \n",
       "STNAME  CTYNAME                                           \n",
       "Alabama Autauga County            55290            55347  \n",
       "        Baldwin County           199713           203709  \n",
       "        Barbour County            26815            26489  \n",
       "        Bibb County               22549            22583  \n",
       "        Blount County             57658            57673  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df의 colum들 리스트에서 column 이름들을 하나씩 뽑아와서 col이라고 하고\n",
    "for col in df.columns:\n",
    "    # 그 이름(col)의 앞글자 2개가 01이면\n",
    "    if col[:2]=='01':\n",
    "        # 원본 df에 있는 columns 중 그 이름(col)을 : 'Gold' + col의 4번째 글자부터 끝까지 로 바꾼다(inplace = True).\n",
    "        df.rename(columns={col:'Gold' + col[4:]}, inplace=True)\n",
    "    if col[:2]=='02':\n",
    "        df.rename(columns={col:'Silver' + col[4:]}, inplace=True)\n",
    "    if col[:2]=='03':\n",
    "        df.rename(columns={col:'Bronze' + col[4:]}, inplace=True)\n",
    "    if col[:1]=='№':\n",
    "        df.rename(columns={col:'#' + col[1:]}, inplace=True) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "\n",
    "# Querying a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame에서 값들을 가져오는 여러가지 방법에 대해서 알아봅시다.\n",
    "\n",
    "Boolean making이라고 하는 방법인데요. 원하는 값을 True로 만들 조건식을 넣어서 True 값과 매칭된 행들을 뽑아오는 방법입니다.\n",
    "\n",
    "예를들어 'Gold'의 값이 0보다 큰 행들만 뽑아오고 싶다고 한다면, 아래와 같은 조건식으로 'Gold'에서 값이 0보다 큰 행들을 True로 만들 수 있겠죠.\n",
    "\n",
    "아래의 조건식은 하나의 column의 조건만 선언되어있으므로 뽑혀진 결과값은 Series 형태로 반환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Gold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2890\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gold'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-286-991caa663da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gold'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2973\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2890\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2892\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2893\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gold'"
     ]
    }
   ],
   "source": [
    "df['Gold'] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 True, False로 나온 Series는 필터 같은 역할을 한다고 생각하시면 됩니다.\n",
    "\n",
    "이렇게 만들어진 필터를 우리가 보고 싶은 원래의 데이터 프레임에 덮어씌우면, 우리는 조건식으로 걸러져 True값이 들어간 행의 값들만 뽑아서 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_gold = df.where(df['Gold'] > 0)\n",
    "only_gold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "`df['Gold'] > 0` 라는 필터로 한번 걸러진 `only_gold`의 데이터 갯수는 100개 이고, 원본 데이터 셋의 데이터의 갯수는 147개 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_gold['Gold'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gold'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\n",
    "\n",
    "컬럼의 중간에 데이터가 없는 행들을 `drop()` 해야하는 경우도 있습니다. 그럴 경우에는 `dropna()`라는 특별한 함수를 사용합니다.\n",
    "\n",
    "`axis` 옵션을 사용하여 `dropna()` 함수를 행에 적용할지 열에 적용할지 선택할 수 있습니다. 기본값은 0이고 행에 적용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "only_gold = only_gold.dropna()\n",
    "only_gold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "pandas 개발자들은 역시 똑똑하기 때문에 우리가 번거롭게 `where()`을 Boolean masking을 하게 내버려 두지 않습니다.\n",
    "\n",
    "pandas의 개발자들은 DataFrame의 column을 지정하는 `[]` 안에 column 이름 대신, 조건식을 넣으면 필터링 된 결과값들을 반환할 수 있도록 조치를 해두었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "only_gold = df[df['Gold'] > 0]\n",
    "only_gold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조건식을 두개 이상 중첩할 수도 있습니다.\n",
    "\n",
    "조건식 두개 이상을 다시 조건식으로 연결할 경우 재료가 되는 각 조건식에 `()`를 해주지 않으면 에러가 나거나 또는 결과가 달라질 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df['Gold'] > 0) | (df['Gold.1'] > 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Gold.1'] > 0) & (df['Gold'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "\n",
    "# Indexing Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index가 지정되는 방법.\n",
    "\n",
    "1. Python list를 Series 또는 DataFrame으로 지정하면 index 값이 0,1,2,3 ... 으로 자동으로 지정된다.\n",
    "2. Python dictionary를 Series 또는 DataFrame으로 지정하면 index 값은 dictionary의 key 값이 들어간다.\n",
    "3. CSV 파일 등을 불러올 때는 몇번째 열을 인덱스로 지정할 것인지 옵션으로 지정해 줄 수 있다.\n",
    "4. `set_index()` 함수를 이용하여 특정 열을 임의로 인덱스를 지정할 수도 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "`set_index()`는 파괴적인 연산자 입니다.\n",
    "`set_index()`를 실행하면 기존에 있던 index의 값은 날라가 버리므로 만약 기존의 인덱스 값이 필요하다면 새로운 칼럼을 만들어 저장한 후 `set_index()`를 실행하는 것이 좋습니다.\n",
    "\n",
    "이름이 있는 컬럼이 인덱스로 변경되었을 경우 인덱스 값과 컬럼의 구분을 하기 위해서 판다스는 아래와 같이 인덱스는 아래로 컬럼 값은 위쪽으로 붙여서 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = df.index # 기존에 있던 인덱스 값들을 'country'라는 컬럼에 저장\n",
    "df = df.set_index('Gold') # 'Gold' 칼럼의 값들을 인덱스 값으로 지정\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "특정한 값들이 아니라 pandas에서 임의로 지정하는 인덱스 값을 DataFrame의 인덱스 값으로 지정하면서 원래 있던 인덱스 값을 다시 컬럼으로 되돌려 놓고 싶은 경우에는 `reset_index()`를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "판다스의 개쩌는 기능 중 하나는 멀티 인덱스 기능입니다.\n",
    "\n",
    "잘쓰면 개쩔고 유용한데, 못쓰면 복잡하고 답답한데 빡치기만 할 수 있습니다.\n",
    "\n",
    "데이터 셋을 바꿔서 census.csv를 봅시다.\n",
    "\n",
    "이 통걔에는 크게 세가지 종류의 데이터들이 들어있습니다. 그중 2번과 3번을 구분하는 값은 'SUMLEV' 컬럼의 값으로 들어있습니다.\n",
    "\n",
    "1. 전체에 대한 정보\n",
    "2. states에 대한 요약 정보\n",
    "3. counties에 대한 요약 정보\n",
    "\n",
    "<br>\n",
    "\n",
    "우리는 각각의 couinties의 정보만 보고 싶다면 어떻게 하면 될까요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('census.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "`unique()` 함수를 사용하면 SQL에서 Distinct를 사용한 효과를 볼 수 있습니다.\n",
    "\n",
    "df의 'SUMLEV' 컬럼의 값은 40 또는 50 두 종류의 값들이 들어있습니다. 이중 counties를 나타내는 값은 50입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SUMLEV'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "'SUMLEV' 칼럼의 값이 50인 데이터들만 뽑아옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['SUMLEV'] == 50]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "'SUMLEV' 칼럼의 값이 50인 데이터들 중에서도 어떤 컬럼들의 값들만 보고 싶은지 추려봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['STNAME',\n",
    "                   'CTYNAME',\n",
    "                   'BIRTHS2010',\n",
    "                   'BIRTHS2011',\n",
    "                   'BIRTHS2012',\n",
    "                   'BIRTHS2013',\n",
    "                   'BIRTHS2014',\n",
    "                   'BIRTHS2015',\n",
    "                   'POPESTIMATE2010',\n",
    "                   'POPESTIMATE2011',\n",
    "                   'POPESTIMATE2012',\n",
    "                   'POPESTIMATE2013',\n",
    "                   'POPESTIMATE2014',\n",
    "                   'POPESTIMATE2015']\n",
    "df = df[columns_to_keep]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "'STNAME'(states 이름), 'CTYNAME'(county 이름)으로 인덱싱을 하여 한눈에 어떤 카운티가 어떤 주에 속하고 그것들의 데이터가 어떻게 되는지 확인할 수 있는 데이터 프레임을 만듭니다.\n",
    "\n",
    "`set_index()`를 사용해 두겹으로 인덱싱을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['STNAME', 'CTYNAME'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "멀티 인덱싱 된 데이터 프레임의 값에 접근하는 방법은 다음과 같습니다. \n",
    "\n",
    "튜플 자료구조형을 사용하면 여러개의 멀티인덱싱된 데이터를 참조할 수도 있습니다.\n",
    "\n",
    "<주의>인덱스가 위치한 순서 그대로 괄호 안에 인덱스 라벨 값을 넣어줘야만 합니다. CTYNAME, STNAME으로 바꿔서 접근하면 에러납니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Michigan', 'Washtenaw County']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ [('Michigan', 'Washtenaw County'),\n",
    "         ('Michigan', 'Wayne County')] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\n",
    "\n",
    "\n",
    "# Missing values\n",
    "\n",
    "데이터 클리닝에서 결측치를 핸들링하는 것은 굉장히 흔한 일입니다. 판다스에서는 결측치를 어떻게 메꿀 수 있는지 알아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('log.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fillna()`를 사용하면 결측치를 한번에 하나의 값으로 메꿀 수도 있습니다. `value` 옵션을 사용하면 됩니다.\n",
    "\n",
    "`method` 옵션에서 `'ffill'`를 설정해주면 앞에있는 행의 값으로 결측치가 자동으로 채워집니다. 이 옵션을 사용할 때에는 데이터가 내가 원하는 대로 잘 정렬이 되어있는지 반드시 확인을 해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "`method = 'ffill'`를 사용하기 위해 적절한 정렬을 해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('time')\n",
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df = df.set_index(['time', 'user'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정렬이 끝났습니다. `method='ffill'`을 사용하여 앞에 있는 값들로 결측치를 채워봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\\\n",
    "<br>\\\n",
    "<br>\\\n",
    "<br>\n",
    "\n",
    "수고하셨습니다 :)\n",
    "\n",
    "이 강의 노트를 참고하며 assignment를 풀어주시면 됩니다.\n",
    "\n",
    "생각보다 과제의 난이도가 높습니다. 하지만 제가 다 풀었으니 여러분도 할 수 있어요! 힘내세요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
