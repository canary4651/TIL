# statistics_06

회식에서 맥주와 소주 중 어떤 술을 먹는 것이 다음 날 숙취가 더 심한지 알아보는 실험을 하려고 합니다. 이 실험에 대한 설명으로 올바른 것을 **모두** 골라보세요. *

독립변수는 "회식에서 먹는 술의 종류"이다

실험에는 "맥주"와 "소주", 2가지 조건이 있다

종속변수는 "다음 날 숙취"이다

회식날 먹은 메뉴가 혼입변수가 될 수 있다

다음 중 실험인 것을 **모두** 골라보세요. *

날씨에 따른 수업의 출석률의 차이를 조사하였다

아침에 일어났을 때 느낀 수면의 질을 측정하여, 수업에서 집중도와의 관계를 분석하였다

버티컬 마우스와 일반 마우스를 쓰는 사람들을 모아 손목 건강이 어떻게 다른지 알아보았다

사람들에게 무작위로 다른 커피를 마시게 하고 신체 반응이 어떻게 달라지는지 알아보았다

실험 설계에 대한 설명으로 올바른 것을 **모두** 골라 보세요. *

조건마다 다른 참여자를 할당하는 것을 between-subject 설계라 한다

between-subject에서는 참여자를 무작위로 할당하는 것이 중요하다

같은 참여자가 모든 조건에 참여하는 것을 within-subject 설계라 한다

within-subject 설계에서는 외생변수를 완벽하게 통제할수 있다

within-subject 설계에서는 참여한 조건의 순서가 실험 결과에 영향을 줄 수 있으므로 순서를 무작위로 할 필요가 있다

두 집단의 평균 차이를 검정하기 위해 부트스트래핑 할 때는 *

두 집단이 원래 같다고 가정한다

두 집단이 원래 다르다고 가정한다

두 집단의 평균 차이를 검정하기 위해 부트스트래핑 할 때는 *

집단을 무시하고 데이터를 섞은 후, 2개의 샘플을 리샘플링으로 뽑는다

각 집단의 데이터에서 1개씩 샘플을 리샘플링하여 뽑는다

두 집단의 평균 차이를 검정하기 위해 부트스트래핑 할 때는 *

2개의 샘플에서 평균 차이를 구하여 그 신뢰구간을 구한다

각 샘플의 신뢰구간을 구한다

두 집단이 다르다고 결론을 내리려면, 실험을 통해 관찰된 두 집단의 차이가 부트스트래핑을 통해 알아낸 신뢰구간의 *

범위 안에 들어와야 한다

범위 밖으로 벗어나야 한다

다음 중 1종 오류와 2종 오류에 대한 설명으로 올바른 것을 **모두** 고르세요 *

1종 오류란 두 집단에 차이가 없는 데, 있다는 결론을 잘못 내리는 경우

2종 오류란 두 집단에 차이가 있는 데, 없다는 결론을 잘못 내리는 경우

부트스트래핑에서 평균 차이의 95% 신뢰구간을 구했다면 신뢰수준은 95%이다

신뢰수준이 95%이면 유의수준은 5%이다

유의수준이 5%이면 5%의 경우에는 1종 오류가 발생한다

신뢰수준을 높이면 2종 오류는 감소한다 → 높아진다. 

- 1종오류와 2종 오류에 대한 설명으로 올바른 것? : 1, 2, 3, 4, 5

 " 데이터를 충분히 고문하면 놈은 불게 되어있다 "

30-40% 재현성 위기 

파워포즈.. 진짜 일까? 

- 귀무가설 : 같다고 가정을 하고 분석하지만 결국 우리가 원하는 건 다르다는 결론: 같다고 시작하지면 결국 이것은 무로 돌아간다(귀무) null hypothesis

# 효과 크기 : 5. 실험의 24p

- 관찰된 현상의 크기를 나타내는 방법
- 분산을 이용하는 방법 → 분산 ~%를 설명 : 에타제곱
- 평균 차이를 이용하는 방법 → ~ 표준편차 차이가 난다 : 코헨의d

## 에타제곱 eta squared → 그리스 알파벳 외우세요

### → 주피터 노트북 실습 : sleep

- 개인차: 집단 간 차이 (16%) 이면 + 집단 내 차이는 84% 이다. 그러니까 결국 집단 간 차이는 베게의 차이(우리 회사 베게를 썼냐 안 썻냐) 그리고 84%는 그냥 순수한 개인 차(사람마다 잠을 잘 자거나 못 자는 차이)
- 편차제곱합(SS): 평균과 차이를 제곱해서 모두 더한 것
- 분산 = 편차제곱합/N
- 전체 SS = (X – 전체평균)**2의 합계
- 처치 SS = (집단평균 - 전체평균)**2의 합계
- 에타제곱 = 처치ss/전체ss
- 개인차 = 집단 간 차이 + 집단 내 차이
    - 에타 제곱 : 집단 간 차이 / 전체 차이 → 그러니까 개인차 중에서 집단 간 차이 부분을 보는 것
    - ex) 한국 과 노르웨이 사람들 간의 키 차이 중에 한국 내 차이가 궁금한 게 아니라 노르웨이와 한국 간의 차이가 궁금한 거

## 에타제곱의 의미

1. 대조군 데이터는 1, 1, 1이고, 실험군 데이터는 3, 3, 3인 경우
• 집단 내 차이는 없고, **집단 간 차이**만 존재
• 에타 제곱 = 1 → 집단 간 차이가 100% 설명 
2.  대조군 데이터는 1, 2, 3이고, 실험군 데이터도 1, 2, 3인 경우
• **집단 내 차이**만 있고, 집단 간 차이는 없음
• 에타 제곱 = 0 → 집단 간 차이가 0% 설명 (집단으론 설명할 수 없음. 아무 의미가 없다) 

### 결론

- **에타 제곱 = 1**
• 집단 간 차이만 있고 집단 내 차이는 없음
• 실험 조건에 따라 모든 것이 달라짐
• 실험 조건이 같으면 결과도 같음
- **에타 제곱 = 0**
• 집단 간 차이는 없고 집단 내 차이만 있음
• 실험 조건에 따라 아무 것도 달라지지 않음
• 같은 실험 조건에도 서로 다름

## 코헨의 d (cohen's d)

- 두 집단의 평균 차이를 데이터의 표준편차로 나눈 것
- 평균 차이의 크기를 알기 쉽게 나타낸 것
- 사람과 관련된 데이터에서는 0.5 정도의 차이도 쉽지 않다

# 설문 문항 만들기

- 한 번에 한 가지만 물어본다
- 응답을 수치화 하기 쉬운 형태로 질문한다

## 리커트 척도 likert scale

- 질문 하나를 던지고 얼마나 동의하는 지를 물어봄
- 그렇다/아니다를 단계로 나누어 질문
    - 전혀 그렇지 않다(1)
    - 약간 그렇지 않다(2)
    - 보통이다(3) → 우리나라 사람들은 보통이 있으면 그냥 3점을 하는 경향이 있어서 빼기도 함
    - 약간 그렇다(4)
    - 매우 그렇다(5)

## 거트만 척도

- 질문을 여러 개 하는 데 강도 순으로 응답하기
- 답변을 약한 것에서 강한 것 순으로 늘어놓은 것
• 외국인들이 우리 나라에 살아도 된다 (1)
• 외국인들이 우리 지역에 살아도 된다 (2)
• 외국인들이 우리 동네에 살아도 된다 (3)
• 외국인들이 우리 옆집에 살아도 된다 (4)
• 외국인들이 우리 아이들과 결혼해도 된다 (5)
- 높은 점수에 응답하면 반드시 작은 점수에도 응답하는 관계가 성립해야
- 여러 개의 응답을 만들어야 해서 잘 쓰진 않지만 그래도 리커트 척도보다는 해석하기가 용이하고 응답하는 사람들도 기준을 주니까 편하다.

## 강제 선택형 ipsative

- 객관식 시험 문제와 비슷
- 입사 시험 같은 경우 (특히 인적성 검사)
- 여러 가지 선택지 중에 하나를 고르게 하는 형식
- 객관식 시험처럼 정답이 있는 경우가 아니면 통계 처리가 까다로움 (단점)
- 인성검사 등에만 제한적으로 사용 → 그냥 없는 거라고 생각하세요~

## 설문 문항 간의 상관 관계

- 대부분의 경우 하나의 개념(예: 고객 만족도)는 직접 측정 X
- 여러 문항을 통해 간접적으로 측정됨
- 하나의 개념을 측정하는 문항들 사이에는 상관 관계
- **진점수 이론 (true score theory)** :  우리가 어떤 진짜 고객 만족도를 측정하고 싶을 때
    - 설문 x = 진짜 고객 만족도 t → 그럼 두 개가 같은 게 아니라
    - X = T + E (오차) 가 존재
    - 미지수가 2개이면 풀 수 없는 문제..! 그치만 설문은 여러가지 문항이 존재한다
    - x1 = t + e1
    - x2 = t +e2
    - x3 = t + t3
    - → 결국 다 만족도를 물어봄. t는 동일하고 오차 e들만 다름
    - 총점 = T + 오차 합계(0)
    - 가설:질문마다 +- 차이가 다 존재하기 때문에 운이 좋다면 다 더해서 0이 되지 않을까?) → 그래서 결국 우리가 물어본 설문 **총점 = T** 일 거라는 이론!

### 실습

- 성격형용사 : ocean (개방/성실/외향/순응/신경질)
- 척도 방식은 섞어도 되긴하는데, 응답자가 혼란스러워 할 수도 있음
- **추석에 가족 모임에 대한 사용자 경험 (포괄적으로) : 주제: 추석 때의 가족 모임 가는 것에 대한 선호도**
    - 사용자 경험을 떨어뜨리는 요인들로 척도를 만들기 - 서비스 디자인을 어떻게 바꿀 것인가?
    - 거트만 척도 사용해도 됨 ex) 친척 간의 질문 - 1 연봉 5 내가 너 앞으로 통장을,,,
    - 3 -4 문항 정도 설문 문항 만들기 : 공통 요소  (더했을 때 결국 공통 요소에 대한 진점수를 찾아야하니까)
        - 1. 친척모임의 사람들과 얼마나 친밀함을 느끼는지? → 4,5부터 개월이 애매 : 친한 데 못만날 수도 있고,,, 사이 나쁜데 같은 반 일 수도 있고../ 굳이 객관적인 숫자가 아니라 주관적으로 문항을 구성해도 됨 → 친밀감의 정도로..? : 결국  쪼개서 문항 구성하면 된다
            - 거트만 척도 1 -5
            - 1: 원수 같은 사이다
            - 2: 명절 때 만나지만 그 외 연락은 하지 않는다.
            - 3: 명절 때만 모이지만 연락을 계속 한다. (일년에 한 두번)
            - 4: 4-5개월에 한번씩 만난다. 친구 처럼 친하다
            - 5: 아주 친해서 1-2개월에 한번씩 만난다.
        - 2. 친척들의 민감한 질문에 대한 나의 불쾌감 정도 → 큰용돈 + 무례한 질문 이렇게 섞여있을 수 있음 / 덕담하고 질문은 다른 내용 / 덕담의 수준이 애매모호 —→ 쪼개면 괜찮아 짐
            - 1 : 큰 용돈을 주시며 덕담을 해주신다
            - 2: 용돈을 주시며 덕담을 해주신다
            - 3: 덕담을 해주신다
            - 4 : 무례한 질문을 1-2번 한다.
            - 5 : 훈계 수준의 무례한 질문들을 계속 이어서 한다
        - 설문은 복잡하고 세세한 문항들을 생각해야하구나
            - 개인 - 프차 카페 선호도 → 근데 문항들을 쪼개야함 왜냐면 카페 의자, 카페 음악 등등 고려 사항이 많음
        - 설문에 편견적인 내용이 들어가있다면?
            - 만든 사람도 사람이니까 설문에 편견이 들어갈 수도 있다.
            - 알 수 있는 방법? : 설문을 만들면 그냥 만들고 끝나는 게 아니라 무언가를 함. 그 때 진실의 순간이 옴
            - 설문을 잘 못 만들면 하려고 했던 일이 되지 않음

# 6. MAB (multi-armed bandit)

## 탐색과 활용

- 탐색(exploration): 기존과 다른 시도
- 활용(exploitation): 기존의 방법을 계속
- 탐색을 많이 하면 개선의 기회가 많지만, 시간 낭비를 할 위험도 큼
- 탐색과 활용을 어떤 비율로 어떻게 할 것인가?

## 외팔이 강도 one-armed bandit

## 여러 팔 강도 multi-armed bandit

- 슬롯머신이 여러 개 있을 때 '터지는' 비율이 다름
- 어떤 슬롯머신을 '당길' 것인가?

## 탐색만 하는 전략

- 모든 슬롯머신을 골고루 당겨본다 : 활용
- 각 슬롯머신의 수익률을 가장 정확히 파악할 수 있음 :
- 돈은 모든 슬롯머신의 평균만큼만 벌 수 있음

## mab 문제의 다른 예

- 홈페이지 디자인의 a안과 b안이 있을 경우
- 디자인에 따라 수익률이 다름
- 모든 고객에게 다른 디자인을 보여준다 → a/b 테스트 → 탐색

## 용어

- 행동(action): 하나의 선택 (슬롯머신, 홈페이지의 디자인)
- 보상(reward): 각 선택의 결과 (발생한 수익)
- 가치(value): 각 행동에 따르는 보상의 평균
- MAB 문제는 행동의 가치 추정하는 문제로 볼 수도 있음
- 우리의 목적 : 보상을 장기적으로 향상 시키는 것

## 탐욕법 greedy algorithm

- 가장 가치가 높은 행동만 한다 (활용 중심)
- 일정 비율(ε, epsilon)만큼은 탐색
- 보통 수학에서 쓰이는 입실론ε (매우 작음이란 의미) → 탐색을 많이 쓰진 않는다 : 거의 5-10%
- epsilon-first: 처음에 ε만큼은 탐색을 하고 이후로는 활용
    - 전략이라고 하기엔 애매. 왜냐면 다들 그냥 하고 있음 (한번 해서 괜찮으면 계속 그걸로만 간다는 전략)
- epsilon-greedy: 매번 ε의 확률로 탐색(5-10%만 실험을 함), 그렇지 않으면 활용
- 낙관적 초기화 : 새로운 옵션에 초기값을 많이 줌 (그러면 새로운 옵션에 기회가 많이 감)  → 결국에는 실제 데이터를 따라감

## 입실론 퍼스트의 예

- 슬롯머신을 각각 100번씩 당겨본 후, 그 후로는 가치가 가장 높은 슬롯
머신만 당긴다
- 홈페이지 디자인 A안과 B안을 1만명의 고객에게 무작위로 보여준 후,
가치가 더 높은 디자인을 골라 모든 고객에게 보여준다

## 입실론 퍼스트의 문제점

- 충분히 탐색을 하지 못할 가능성
    - 100번으로는 슬롯머신의 가치를 충분히 정확히 추정하기에 부족하다면?

- 시간에 따라 변화하는 상황에 대응하지 못함  (더이상 테스트를 안하기 때문)
    - 여름에 실험한 결과는 겨울에 통하지 않는다면?

## 입실론 그리디의 예

- 주사위를 굴려서 1이 나오면 무작위로 아무 슬롯머신이나 당겨보고, 그
외에는 이제까지 가치가 가장 높은 슬롯 머신을 당긴다
- 20%의 고객에게는 A안과 B안 중에 무작위로 보여주지만(입실론 실험), 나머지 80%
의 고객에게는 이제까지 가치가 가장 높은 슬롯 머신을 당긴다

## 입실론 그리디의 문제점

- 기존의 데이터가 많이 누적되면 상황이 변하더라도 반영이 잘 되지 않
음

[입실론 그리디의 문제점 예시](https://www.notion.so/f26a92158b674f01807c849898a87ff4)

- 여름에 많은 데이터가 쌓여있을 경우 겨울이 되어도 새로운 데이터가
상대적으로 적으므로 B의 가치가 A의 가치를 빨리 따라잡지 못함

### 실습 : 주피터 노트북 참조 (통계 5)

## 이동 평균

- 일반적인 평균 계산법
- 이동 평균 : 합계를 구하지 않고 평균을 구함. 수학적으로는 동일
    - 𝑉𝑛−1: 기존의 가치
    - 𝑅𝑛: 새로운 보상
- 새로운 보상 > 기존의 가치 → 가치를 UP
- 새로운 보상 < 기존의 가치 → 가치를 DOWN

## 이동 평균의 식으로 보는 입실론 그리디의 문제

- V는 새로운 데이터에 1/N만큼만 영향을 받는다
- 데이터가 쌓일 수록 N이 증가하므로
- 새로운 데이터에 받는 영향이 감소

## 지수이동평균

𝑉𝑛 ← 𝑉(𝑛−1) + 𝑎(𝑅𝑛 − 𝑉(𝑛−1)) → 여기 식에서 -1은 진짜 -1이 아니라 작은 n-1 거임...

- 새로운 데이터가 주는 영향을 1/N에서 a로 고정 (0 < a < 1)
- 기존의 데이터가 남긴 영향은 점점 (지수적으로) 사라짐
- a가 클 수록 새로운 데이터에 민감

## 결론 : 입실론 그리디 + 지수이동평균의 파라미터

- 지수이동평균과 입실론 그리디를 합쳐서 쓰면 mab 문제의 간단한 해결책을 쓸 수 있다
- ε: 크면 탐색을 많이, 작으면 활용을 많이 : 얼마나 실험을 할거냐는 지수
- a: 크면 최근 데이터에 민감 : 얼마나 트렌트를 따라갈 거라는 지수
- 전체 보상이 극대화되도록 두 가지를 조정

### UCB 알고리즘

- upper confidence bound: 신뢰구간의 위쪽 경계
- 각 행동의 가치에는 신뢰구간이 있음
- 가치의 신뢰구간 위쪽을 기준으로 행동을 선택
- 적게 한 행동 → 샘플이 작음 → 신뢰구간이 넓음 → 가치 낮아도 선택

### 그 외의 알고리즘

- 톰슨 샘플링 (복잡한 계산)  : 요즘 쓰는 서비스
    - 가치 대신 각 행동의 가치의 분포를 추정
    - 분포에서 무작위로 샘플링을 하여 높은 가치가 추정된 행동을 선택
    - 행동 후 보상을 얻으면 분포를 수정
    - 구글 등에서 사용하는 알고리즘. 수학/통계 지식이 필요
    - optimizely 라는 서비스가 유명
    - [카카오 추천시스템 돈이 되어야 : 파이콘 '최규민' 한번 읽어보기](https://www.pycon.kr/program/talk-detail?id=136)
    - [https://www.slideshare.net/ssuser2fe594/ss-164511610?fbclid=IwAR2qpRcMCddxqVC0WHX9Uq_n7P4OwN7CX_90Bsv3WLc6A_FKNWPWBwSPbTM](https://www.slideshare.net/ssuser2fe594/ss-164511610?fbclid=IwAR2qpRcMCddxqVC0WHX9Uq_n7P4OwN7CX_90Bsv3WLc6A_FKNWPWBwSPbTM)

- 소프트맥스 알고리즘
    - 행동의 가치를 직접 추정하는 대신 행동마다 확률을 부여
    - 행동을 하고 높은 보상을 얻으면, 그 행동의 확률을 높임 (낮으면 낮춤)