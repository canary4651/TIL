# statistics_08

## 통계08 파일

# 잔차 residual

- 회귀 분석의 예측과 실제값의 차이 (남아있는 차이)
- 잔차의 분포에서 주목하는 특성들
    - 왜도
    - 첨도
    - 등분산성

## 왜도 skewness

- 분포의 비대칭성
- negative skew : 오른쪽으로 늘어짐
- positive skew : 왼쪽으로 늘어짐
    - ex) 소득 = postivie skew 라면 부자들은 극단적으로 돈이 많은거..!

![](Untitled-1542ac4a-3e26-4529-bf11-2c1c2ca749ba.png)

## 첨도 kurtosis

- 분포가 한 점에 몰린 정도 (노트필기 참고)
- 정규분포의 첨도 = 3
    - 대충 3 근처면 정규분포와 비슷한 모양이다
- 첨도가 높다 → 데이터가 중심에 몰려 있음
- 첨도가 낮다 → 데이터가 바깥으로 퍼져 있음
- 정규분포와 너무 극단적인 값이 나오면 확인해보기

## 잔차의 정규성 normality

- 잔차가 정규분포에 가까운 성질을 가지고 있는가?
- omnibus/ jarque-bera
- 둘다 prob가 1에 가까울 수록 정규분포에 가까움
- 크게 문제가 되는 값은 아니기 때문에 너무 이상하지만 않으면 됌

## 등분산성 homoscedasticity

- 등분산성 개념은 중요! (노트필기 참고)
- 분산이 같다
- 모든 범위에서 잔차의 분산이 같음
- 쉽게 말해 어떤 x에서든 비슷한 정도로 y를 맞출 수 있음
- Dubin-Watson 통계량이 1~2 정도 (적당)

## 조건수 condition number

- 통계를 넘어가는 수학적 개념
- 입력의 변화에 따른 출력의 변화를 나타내는 수
- 조건수가 크면 → 데이터가 조금만 달라져도 결과에 큰 차이
- 통상 30 이하
- 크게 나올 땐 미친듯이 크게 나옴 - 밑에 다중공선성 때문에!

## 다중공선성 multicollinearity

- 노트 필기 참고
- 중요한 개념 : 조건수를 확인해야 하는 이유
- 여러가지(다중)가 함께(공) 직선(선)을 만든다
- 독립변수들이 서로 예측가능할 경우
- 조건수가 커짐
- 데이터나 변수의 변화에 따라 추정된 계수가 크게 달라짐

## 정리

- 잔차의 다른 개념들은 굳이 확인 안 해도 되지만  다중공선성 - 조건수 는 봐줘야 함
- 다중공선성 (독립변수끼리 예측) 발생
- 계수 추정이 불안정 해짐 (너무 많아지니까)
- = 조건수가 높음

# 변수선택

## 교차검증 Cross Validation

- 데이터를 무작위로 두 세트로 나눔
- 한 세트에서 추정 → 다른 세트에서 검증
- 위 과정을 반복

## k-fold Cross Validation

- 데이터를 k개로 나누어 CV를 k번 하는 방법
- 예) k=3일 경우
    - 1, 2번 데이터로 추정 → 3번 데이터로 검증
    - 2, 3번 데이터로 추정 → 1번 데이터로 검증
    - 1, 3번 데이터로 추정 → 2번 데이터로 검증

## 정규화 Regularization

- 과적합(overfitting): 모형의 계수가 주어진 데이터(sample)에 지나치게 의존하여 추정되는 경우 : 샘플에만 치우친 결론을 내는 것
- 과적합이 생기는 경우 : 변수가 많을 수록, 계수가 클 수록 과적합의 위험이 큼 (노트필기 참고)
    - 1) 변수가 많으면: 회귀분석은 독립변수가 1일때 직선을 찾는 건고(2차원일때), 독립변수가 2개일 때 평면을 찾는(3차원) 건데 데이터가 3개가 있다면 2차원에서는 찾기 어렵고 3차원은 2개를 관통하니까 찾을 수 있다. 직선이면 솔직히 어떨 때는 데이터들을 다 포함 못 시킬 수 있음(직선은 추세선이니까) 근데 3차원인 평면들은 직선보단 더 많이 포함할 수 있음(추세면) 그래서 과적합이 생길 확률이 더 크다. → 모형이 설명할 수 있는 능력을 계속 제한하면 과적합도 안 된다 (직선 > 곡선)
    - 2) 계수가 클수록? : 예를 들면) 기울기의 범위가 +-1을 못 넘는다고 하면, 직선이 fit되는 범위가 좁아짐 → 예측에 맞기가 어려움
    - 반대로: 계수의 범위를 제한하면, 잘 안 맞기 쉬워짐 → 과적합이 잘 안됨
    - 과적합을 막는 이유 - 예측을 잘 하기 위해
    - 변수는 빼/안빼거나 두 경우 → 경우의 수 조합 (10개면 2e10 개...고려... 100개면 2e100승...) : 물리적으로 하나씩 넣고 빼는 게 어려움 그래서 변수 선택을 하나하나 안함
- 만약 계수가 0이라면 변수를 추가하지 않은 것과 같음
- 정규화: 가능한 계수를 작게 추정하는 방법
    - 선형모형 : 계수는 상관없고 오차(mse)만 작으면 된다! 요건데 정규화는! 아니! 계수도 작아야해! 라는 거 → 과적합을 막기위해 →왜? 예측이 잘 되기 위해

## 정리

- 1) 변수가 작아야 하고
- 2) 계수가 작아야 한다 → 정규화
- 곡선 x 직선

## 회귀분석에서 정규화

- 보통 회귀분석은 y의 예측에 대한 오차(MSE)를 최소화
- 그렇지만 회귀분석에서 정규화는! (오차 + 계수)를 최소화 하도록 함 (둘다 가능한 줄이자!)
- 오차가 조금 늘어나더라도 계수를 작게 만들어 과적합을 방

## 라쏘 회귀분석 Lasso

- 계수의 절대값을 최소화

![](Untitled-dd532371-e0b2-4906-86cb-8defa817f8a0.png)

- 𝜆(람다): **클 수록** 계수를 최소화하는 데 더 큰 비중
- 회귀계수를 0으로 만드는 경향 → 변수 선택

## 릿지 회귀 분석 Ridge

- 라쏘는 계수에 절대값을 씌운 거고, 릿지는 제곱을 해줌
- 계수의 제곱을 최소화

![](Untitled-207b9788-7c41-4257-9b62-a939fa36d926.png)

- **라쏘보다 대체로 나음.** 회귀계수가 0이 되지는 않음
    - 그러면 릿지를 아예 안 쓰면 되지 않나? → 그치만 계수를 0으로 만들면 빼는 거랑 동일한 거니까 해석이 심플해짐. 그래서 릿지도 씀
- 딥러닝에서 "가중치 감쇠(weight decay)"라고 부름

## 엘라스틱 넷 Elastic Net

- 라쏘 + 릿지

![](Untitled-4203e2c1-915a-490e-81b6-557291083f05.png)

- a = 1: 라쏘
- a = 0: 릿지

## 하이퍼파라미터 hyperparameter

- 모형의 특성을 결정**하지만** 데이터로부터 학습되지 않는 값
- 계수는 파라미터이며 데이터로부터 학습하는 값인데, 파이퍼파라미터는 데이터로부터 학습되지 않는 값 (계수를 줄이는 게 mse(오차)를 줄이는 게 더 중요하다고 내가 정한거, 내 맘임)
- 엘라스틱 넷에서 𝜆와 a
- CV를 통해 결정 (교차검정)

## 정리

- |계수| → 라쏘
- 계수e2 ⇒ 릿지
- 엘라스틱 넷 (라쏘 + 릿지) 를 CV를 통해 결정 → 하이퍼파라미터
- 실습

# 회귀분석 고급

## 더미코딩 dummy coding

- 독립변수에 이산형(범주형) 변수가 있을 경우
    - 짜장, 짬뽕, 볶음밥
- 기준이 되는 값을 정함 : 짜장
- 나머지 값을 새로운 변수로 추가 : 짬뽕, 볶음밥
- 해당되는 변수의 값을 1, 나머지는 0으로 설정

![](Untitled-341b533d-1dd2-4002-906a-133eff54d2f7.png)

- 왜 짜장 변수는 안만들까? 기본이 짜장 값이기 때문에 짜장 - 짜장 → 다중공산성 때문! (위에서 배운내용)

## 더미 코딩의 해석

- 점심_짬뽕의 계수 → 기준(짜장)과 짬뽕의 집단 간 차이
- 점심_볶음밥의 계수 → 기준(짜장)과 볶음밥의 집단 간 차이
- 실습 (주피터 파일 확인)

## 상호작용 interaction

- 두 독립변수의 곱으로 이뤄진 항(xm)
𝑦 = 𝑥 + 𝑚 + 𝑥𝑚
- 상호작용에 넣을 지 말 지 판단은 분석가의 몫
- 간단히 하기 위해 m은 0 또는 1만 갖는 범주형 변수라 하자
    - 아니어도 됨 (해석을 쉽게 하기 위해서 걍 함)
    - m : 남자/여자
    - xm = 상호작용항

## 상호작용이 없는 경우

- m에 따라 x의 절편이 바뀌는 것으로 해석
    - y = x + m
    - 남/녀 운동시간에 따른 근육량 증가가 똑같을 거야! 라는 가설

    ![](Untitled-b6b003ef-7d22-4e3f-a517-e48994b5e005.png)

    - 각각 계수 m (1이거나 0) 일 때 x에 따라 y가 달라짐 - 그냥 직선이 반듯하게 위로만 올라감

## 상호작용이 있는 경우(1)

- m에 따라 x의 기울기가 바뀌는 것으로 해석
    - 절편은 같겠지~
    - 러시아어 안 배운 남/여 학습량에 따른 러시아어 증가 할 때 습득 속도가 다를 때 (제로베이스라는 디폴트 값이 다름)
    - y = x + xm

    ![](Untitled-0e7fd4a9-6ff0-4ddc-96ed-c69c74ac7df6.png)

    - y = (1 +m)x
    - y = (a+mb)x → (a+mb) 를 계수로 봄
        - m=1 → a+b
        - m=0 → a

## 상호작용이 있는 경우(2)

- m에 따라 x의 절편과 기울기가 바뀌는 것으로 해석
- y = x +m +xm
- 남/녀 운동시간에 따른 근육량 증가가 다를 거야! 라는 가설 → 신뢰 구간 비교해서 결정하면 됨 (둘다 돌려보고) - 근육량의 디플트 값이 다르니까

![](Untitled-c77acf23-12fd-4bce-924a-fd75b35845fe.png)

- y = (1+m)x + m
- 이 그래프는 기울기가 마이너스 값일 때..!
- 다르게 그릴 수도 있음 (노트 참고)

### 실습 통계파일08

- 노트필기 참고

## 정리 : 그래프 노트정리

### 상호작용이 없는 경우

- y = ax + bm + c
- m = 0 : ax + c
- m =1 : ax + (b+c)

### 상호작용이 있는 경우 1

- y = ax + bm:x + c
- m = 0 : ax + c
- m = 1 : (a+b)x + c

### 상호작용이 있는 경우 2

- y = ax + bx:m + cm + d
- m =0 : ax + d
- m = 1 : (a+b)x + c + d

# 복습 테스트

1. **다음 각 문제를 분석하려고 할 때, "선형 모형"과 "로지스틱 선형 모형" 중 더 적절한 모형을 고르세요. ***

    배우의 연기력이 영화를 관람한 관객수에 미치는 영향

    담당 직원의 친절도가 고객의 재구매 여부에 미치는 영향

    고객의 나이와 성별이 구매 액수에 미치는 영향

    환자의 생활습관과 의사의 실력이 질병의 회복 여부에 미치는 영향

    tip) '여부'가 나오면 로지스틱 선형 모형이라고 생각해라 

2. **실험을 하고 신뢰구간을 구해봤더니 신뢰구간이 우리가 필요로 하는 범위보다 넓었습니다. 무엇을 해야 합니까?** *

    더 많은 실험을 해서 샘플의 크기를 키운다

    부트스트래핑에서 리샘플링을 더 많이 한다 → 그냥 원래 많이 해야하는 거 

    부트스트래핑에서 리샘플링을 줄인다

    일단 컴퓨터를 끄고 퇴근한다

3. **두 집단의 평균 차이를 검정하기 위해 부트스트래핑 할 때는** *

    두 집단이 원래 같다고 가정한다

    두 집단이 원래 다르다고 가정한다

4. **두 집단의 평균 차이를 검정하기 위해 부트스트래핑 할 때는** *

    집단을 무시하고 데이터를 섞은 후, 2개의 샘플을 리샘플링으로 뽑는다

    각 집단의 데이터에서 1개씩 샘플을 리샘플링하여 뽑는다

5. **두 집단의 평균 차이를 검정하기 위해 부트스트래핑 할 때는** *

    2개의 샘플에서 평균 차이를 구하여 그 신뢰구간을 구한다

    각 샘플의 신뢰구간을 구한다

6. **두 집단이 다르다고 결론을 내리려면, 실험을 통해 관찰된 두 집단의 차이가 부트스트래핑을 통해 알아낸 신뢰구간의** *

    범위 안에 들어와야 한다

    범위 밖으로 벗어나야 한다

7. **상관계수에 대한 설명으로 올바른 것을 **모두** 골라보세요.** *

    두 변수가 얼마나 관련이 있는지 나타낸다

    U자형의 비선형적인 관계도 나타낼 수 있다  → 좀 더 정확하게는 그 수치는 0

    -1에서 1까지 범위를 가진다

    한 변수가 증가할 때 다른 변수도 증가하면 +가 된다

    한 변수가 증가할 때 다른 변수는 감소하면 -가 된다

    서열의 상관을 구할 때는 스피어만 상관계수나 켄달 상관계수를 사용한다

8. **선형 회귀분석을 실시한 결과 R제곱(R-squared)가 0.8이 나왔습니다. 분석 모형은 종속변수의 분산의 몇 %를 설명합니까?** *

    20%

    40%

    60%

    80%

9. **다음 중 선형 회귀분석의 모형을 비교할 때 사용하는 적합도 지수를 **모두** 고르세요** *

    R-squared

    Adj. R-squared

    Log-Likelihood

    AIC

    BIC

10. **선형 회귀분석에서 회귀계수의 신뢰구간은 어떠해야 합니까?** *

    플러스와 마이너스에 고르게 걸쳐 있어야 한다

    플러스에만 있어야 한다

    마이너스에만 있어야 한다

    플러스든 마이너스든 어느 한쪽에만 있어야 한다