# statistics_07

# 예측

- 회귀분석
- 예측의 다양한 문제들

# 잠재

- 클러스터링
- 요인분석과 차원축소

# 시간

- 시계열분석과 생존분석
- 마케팅 효과

# 상관

## 산점도 (scatterplot)

- 두 연속 변수의 관계를 시각화
    - 커피의 맛 / 가격
- 한 건의 데이터를 점으로 표시

## 상관 계수

- 공분산을 두 변수의 표준편차로 나눈 것
- 항상 -1 ~ +1 범위
- +1: 완벽하게 같은 방향으로 움직임
- 0: 아무 관계 없음
- -1: 완벽하게 반대 방향으로 움직임
- 상관관계에서 +- 부호의 의미? : 두 관계가 얼마나 직선인가 (직선적인 패턴을 보기 위해)
- 그래서 산점도를 그렸을 때 U자형이 나온다면(0) → 상관관계가 적구나! 라고 생각하기
    - ex) 체중 : 정상 체중보다 약간 과체중이 건강에 좋다 비만은 안 좋음 요런 경우!

![](Untitled-e1bd609e-3e01-428d-ae1f-ad3ada6a6303.png)

## 허위 상관관계 spurious correlation

- 두 변수 사이에 실제로는 관계가 없어도 상관관계가 나타나는 경우
- 데이터가 적을 수록 나타나기 쉽다
- 상관관계의 신뢰구간을 확인 (95%)
- [https://www.tylervigen.com/spurious-correlations](https://www.tylervigen.com/spurious-correlations)
    - 니콜라스 케이지가 영화 찍은 수 ←> 수영장에 빠져 죽는 사람 수 그래프가 상관관계를 보임...ㅋㅋㅋㅋㅋㅋㅋ
    - 불신의 생활화
    - 상식적으로 생각해보기

## 여러 가지 상관계수

- 피어슨(pearson) 상관계수 : 상관계수라고 하면 보통 피어슨 상관계수를 생각한다.
    - 원 데이터 사용
    - p value는 작을수록 좋다
- 서열 사용 : 데이터가 서열만 상관이 있으면 됨, 등수
    - 통계07_liar data
    - 스피어만(spearman) 상관계수 (ρ, 로)
        - 실제 변수값 대신 그 서열을 사용하여 피어슨 상관계수를 계산
        - 한 변수의 서열이 높아지면 다른 변수의 서열도 높아지는지를 나타냄
    - 켄달(kendall) 상관계수 (τ, 타우)
        - 스피어만 상관계수와 비슷하게 서열의 관계를 수치화, 계산 방법이 다름
        - 데이터가 작고, 동점이 많을 때 사용
- 그냥 데이터다, 그래프가 직선 - 피어스
- 등수다, 그래프가 휘어있다- 스피어만 , 켄달
- 모르겠다 - 셋 다 쓰기 ^^
- 그치만 자주 하는 순위 1. 피어스 2. 스피어만 3. 켄달

### 정리

1) bootstrapping 신뢰구간 검정

2) p → 0.05보다 아래 : 작은 값일수록 좋다 

# 회귀분석

## 회귀분석 regression

- 여러가지 의미로 사용
- 데이터의 그래프를 볼 때 (기울기) 가 결국에는 추세선(회귀선)을 따라간다. → 결국 추세를 따라간다는 의미,,,
- 가장 넓은 의미: X → Y 예측 : y = ax + b
- 중간 의미: Y가 연속인 경우(Y가 범주형인 경우는 분류)
- 좁은 의미: 선형 회귀 분석(선형 모형을 이용한 회귀분석) → 통상적으로 가장 많이 씀

## 절편과 계수

- 절편 (intercept): 독립변수가 모두 0일 때 종속변수의 값 : y=b (x=0 일때)
- 계수(coefficient): 독립변수가 1 증가할 때 종속변수의 변화 : x가 1 증가할 때 y의 변화
- 선형모형 배울 때 직접 계수도 구해보고, sklearn으로 구했는데 이번에는 다른 걸(statsmodels)로 해보기
    - 자동차 데이터로 회귀분석

### **선형 모형 돌릴떄는 coef랑 intercept, speed 값만 나오는 데 회귀 모형은 많은 값들이 나옴**

- dist = 3.9(=speed)*speed + (-17.57 = intercept)
- 근데 회귀 분석 모델은 다 나오게 해줌 (coef표 맨 끝에 [0.025 0.975] 95% 신뢰구간까지 다! )
- p>|t| : p값이 0.05랑 비교했을 때..! 해석을 볼 수 있음 (신뢰구간이 둘다 +면 p값이 작게 나옴 -> 신뢰 구간이 +-든 한쪽으로 일정하게 나온다는 뜻)
- p 값 : 변수 하나에 데이터가 충분하냐를 물어봄
- 계수에다가 +- std err*2 를 하면 신뢰구간이 나옴 (신뢰구간을 구하는 과정에서 나오는 수치)
- t: p를 구하는 과정에서 나오는 중간 수치
- ols : ordinary least squard 약자

![](Untitled-0020d892-21b1-4713-8c69-322d1872e3d2.png)

![](Untitled-22d58c6e-8624-48a2-833b-695bb6fe3613.png)

- r-squarred : 에타제곱 (모형 - 적합도 지수) : 65%는 차의 속도로 설명이 된다는 뜻
- adj.r-squared: adjust(보정, 수정) : 에타제곱은 여러가지 변수를 같이 고려하면 증가하는 경향이 있다. (무조건 독립변수가 많은 모형이 낫다는 결론을 내림 : ex) 차량의 속도 - 거리 고려 < 차량의 속도 + 날씨 + 변수 등등.. - 거리 고려) 그래서 여기서 보정을 해줌.
- 회귀 변수에서 독립변수가 하나만 있을 경우, 상관계수를 제곱하면 r 제곱이랑 똑같은 값이 나옴 (수학적 이유로 인해서,,) 그래서 이 표에서도 r제곱은 dist와 speed의 상관 제곱과 같은 값이다! (바꿔 말하면 root씌우면 독립변수와 종속변수의 상관관계값이 나옴) - 독립변수가 하나면 상관계수를 분석하나 회귀 분석을 하나 똑같은데, 이왕이면 많은 값이 나오는 회귀 분석을 하는 게 좋다

## 계수의 신뢰구간

- 표준 오차(standard error): 표본 분포에서 표준 편차
- t: 회귀계수 / 표준오차
- p: 추정된 회귀계수부터 무한대까지 범위
- 회귀계수가 95% 신뢰구간을 벗어난다 = p 값이 5% 아래

## 회귀분석의 적합도 지수 Fit Index

- 모형이 전체적으로 데이터에 얼마나 잘 맞는지(fit)를 나타냄
- 여러 가지 모형이 있을 경우 적합도가 더 좋은 모형은 선택
- R제곱
- F
- 로그우도

## R 제곱 R squared

- R 제곱: 종속변수의 분산 중 회귀분석에 의해 설명되는 비율
- 독립변수가 많을 수록 높아지는 경향이 있음
- 수정 R제곱: 독립변수의 개수를 보정.
- **독립변수 X가 1개인 경우 X와 Y의 상관계수를 제곱하면 R제곱과 같음 =** 독립변수 X가 1개인 경우 X와 Y의 상관계수를 제곱하면 R제곱과 같음 (위에서 이야기 한거!)

## F 통계량 F statistic

- F: 절편을 제외한 모든 회귀 계수가 0일 때를 가정하고 계산한 수치 (다 0이여도 이런 결과가 나올 수 있냐?) - 굉장히 작으면 아니다! 라는 뜻 : 우연이 아니라 이런  상관관계가 나올 수 있다라는 해석 (0.05보다 작아야함 - 만약 크면 데이터가 너무 작은거)
- Prob(F): **p값과 비슷하게 해석 (그냥 p값과 비슷하게 생각해서 0.05보다 작아야 좋다고 생각하자)**
- 1.49e의 의미 e:지수 라고 생각..! 1.49에 -12가 지수다.

![](Untitled-31edbc80-3329-4fe2-b41c-1b623f972000.png)

## 로그 우도 log likelihood

- 예) 스피드에 의해서 dist가 설명되는 모델을 만들었음 - 이 데이터가 관찰될 확률은 얼마냐 = 로그우도 (-206) : 데이터가 나올 확률이 크면 클수록 로그우도에서 점점 올라가게 됨 0(최대값)이 나올 수록 좋다
- 로그 우도: 종속변수가 정규분포라 가정했을 때 그 우도
- 로그 우도도 R제곱과 마찬가지로 독립변수가 많아지면 증가
- AIC와 BIC는 로그 우도를 독립변수의 수로 보정한 것(작을 수록 좋음)

## 정리

- r ,adr : 높을 수록 좋다
- f, prob : 낮을 수록 좋다 : 단순하게 모형 하나만 가지고 이야기할 때, 데이터가 결론을 내리기에 충분하냐를 알려주는 뜻 (0.05 보다 낮아야 함. 높으면 데이터가 충분하지 않은 것)
- log likelihood: 높을수록 좋다
- aic bic : 낮을수록 좋다
- 기본적으론 adj.r이랑 aic bic를 보고 더 좋은 것을 고르면 됨. (보정값들을 쓰는 게 좋다는 말)
- 지금은 prob랑 p값이랑 상관계수 구한값이당 똑같다. 왜냐면 변수가 하나여서 변수에 대한 데이터 값이 모형 하나에 대한 데이터 값이랑 같이 때문에 하나가 충분히 많다는 뜻이면 모형에도 데이터가 충분이 많다는 뜻으로 이어짐
1. 독립변수의 계수를 보고 → 신뢰구간 보고 → ++/ - - 던지 부호가 바뀌지 않아야함 
2. 모형끼리 비교할 때는 porb(f) < 0.05 여야함 (아니면 데이터를 더 모아야함) 
3. 모형끼리 비교할 때 adj.r-squard(높을수록 좋음), aic, bic(낮을 수록 좋음) 로 비교 : 
    - 이 3 수치가 다 좋다는 뜻은 어떤 식으로 가정하더라도 그 모형이 가장 좋다라는 결과

### 해석

그렇지만 모형은 적합도 지수로 고르기 때문에 티비 , 게임 -> 공격성 보다 < 형제(x), tv, 게임 -> 공격성의 지수가 더 높기 때문에 후자 모형을 선택하자! : 형제가 영향을 미친다는 결론은 낼 수 없지만, 지수로 보면 더 크기 때문에 빼면 안 된다.

- -> 이 의견에 의해서 모형이 가장 높은 값은 상관없는 변수들이 있을지라도, 여러개의 독립변수를 둔 모형값이 가장 높다!
- -> **모형 설계와 변수 해석은 다르다**
- 비교는 3가지만 한다 : adj.r제곱, aic, bic
- → 모형 선택 → 변수해석

## 변수 선택 variable selection

- 하나의 종속변수에 영향을 주는 독립변수들 사이에는 관련이 존재
- 변수들이 많을 때 가능한 독립변수의 조합이 다양

## 단계적 회귀분석 Stepwise Regression

- 변수를 단계적으로 추가/삭제하는 방법
- 과거에는 많이 사용했으나 근본적 한계가 있음
- 데이터가 적고, 변수의 수도 적다면 쓸 수도 있음

## 전방 선택 Forward Selection

- 절편만 있는 모형으로 시작 : 아무 독립변수도 넣지 않음
- 추가했을 때 모형을 가장 많이 개선할 수 있는 변수를 추가
- 더이상 모형이 개선되지 않으면 중단
- 지나치게 적은 변수를 포함시킬 위험이 존재 (단점): 너무 일찍 스탑해버림

## 후방 선택 Backward Selection

- 모든 변수를 투입한 모형으로 시작
- 제외했을 때 모형을 가장 많이 개선하는 변수를 제외
- 더 이상 모형이 개선되지 않으면 중단
- 지나치게 많은 변수를 포함시킬 위험이 존재

## 교차 검증 Cross Validation

- 데이터를 무작위로 두 세트로 나눔
- 한 세트에서 추정 → 다른 세트에서 검증
- 위 과정을 반복

# 복습테스트

1. **"주연 배우의 연기력"이 "영화의 흥행"에 영향을 준다는 모형을 만들어 데이터를 분석하려고 합니다. 여기서 독립변수는 무엇인가요? ***

    주연배우의 연기력

    영화의 흥행

**2. 다음 중 선형 모형의 식을 골라 보세요. ***

y = ax + b

y = expit(ax + b)

y = numpy.mean((data - x) ** 2)

**3. 선형 모형의 식에서 파라미터에 해당하는 것을 **모두** 골라 보세요 ***

x

y

a

b

**4. MSE에 대한 설명으로 올바른 것을 **모두** 골라 보세요 ***

오차(Error)를 제곱(Squared)한 것을 평균(Mean)낸 것이다.

제곱 대신 절대값(Absolute value)을 사용하면 MAE가 된다 : (써도 되긴 하는 데 내가 다 계산해야함)

파라미터를 추정할 때는 MSE를 가장 작게 만드는 파라미터를 찾는다

선형 모형에서 MSE를 가장 작게 만드는 파라미터는 항상 하나가 존재한다

**5. 평균의 95% 신뢰구간이란 95%의 샘플에서 나올 수 있는 평균의 범위를 가리킨다 ***

참

거짓

**6. 선형모형 y = ax + b에서 계수 a의 신뢰구간은 ***

마이너스와 플러스 양쪽에 고르게 걸쳐 있어야 한다

마이너스 쪽에만 있어야 한다

플러스 쪽에만 있어야 한다

마이너스든 플러스든 어느 한 쪽에만 있어야 한다

**7. 다음 중 실험인 것을 **모두** 골라보세요. ***

날씨에 따른 수업의 출석률의 차이를 조사하였다 → 개입할 수 없음 

아침에 일어났을 때 느낀 수면의 질을 측정하여, 수업에서 집중도와의 관계를 분석하였다 → 수면의 질을 개입할 수 없음 

버티컬 마우스와 일반 마우스를 쓰는 사람들을 모아 손목 건강이 어떻게 다른지 알아보았다 → '모아' : 개입을 한게 아님. 그냥 쓰는 사람들만 모은거..! 그게아니라 통제 해야함 (개입을 안한거) 

사람들에게 무작위로 다른 커피를 마시게 하고 신체 반응이 어떻게 달라지는지 알아보았다

**8. 다음 중 1종 오류와 2종 오류에 대한 설명으로 올바른 것을 **모두** 고르세요 ***

1종 오류란 두 집단에 차이가 없는 데, 있다는 결론을 잘못 내리는 경우

2종 오류란 두 집단에 차이가 있는 데, 없다는 결론을 잘못 내리는 경우

부트스트래핑에서 평균 차이의 95% 신뢰구간을 구했다면 신뢰수준은 95%이다

신뢰수준이 95%이면 유의수준은 5%이다 → 1종 오류를 5% 감수하겠다

유의수준이 5%이면 5%의 경우에는 1종 오류가 발생한다

신뢰수준을 높이면 2종 오류는 감소한다 → 유의수준이 내려가서 1종 오류가 내려가기 때문에 2종 오류는 증가한다

**9. 베게에 따라 수면시간이 달라지는지 알아보는 실험을 했다. 이 실험에서 에타제곱이 0.8이면 분산의 몇 %가 베게(집단 간 차이)로 설명되는 것인가? ***

20% → 집단 내 차이 

40%

60%

80%

**10. 위의 실험에서 구형 베게 대비 신형 베게의 효과 크기가 코헨의 d로 0.5였다. 만약 수면 시간의 표준편차가 2시간이라면, 신형 베게를 벤 사람들 구형베게를 벤 사람들보다 평균적으로 얼마나 더 자는 것인가? ***

0.5시간

1시간 

→ 코헨의 d : 두 집단의 차이를 표준편차로 나눈것 그래서 이 문제의 답은 (0.5 x 2) 

2시간

**11. 탐색과 활용 문제에 대한 설명으로 옳은 것을 **모두** 골라 보세요. ***

탐색은 새로운 시도를 해보는 것

활용은 기존에 알려진 최선의 것을 하는 것

탐색을 많이 하면 개선의 기회가 많지만 낭비를 할 수 있다

무조건 활용을 많이 하는 것이 좋다

**12. 홈페이지 디자인의 A안과 B안 중에 고민을 하고 있습니다. 이를 MAB 문제로 다룰 때, 아래 설명 중 올바른 것을 **모두** 골라 보세요. ***

A안과 B안을 MAB에서는 '행동'이라고 한다

사용자에게 홈페이지 디자인을 보여주었을 때 얻은 결과(예: 회원가입, 상품구매)를 '보상'이라고 한다

A안의 가치는 A안의 평균적인 보상을 말한다

입실론 그리디 전략을 사용할 때 입실론 = 10%라면, 무작위로 90%의 경우에는 이제껏 알려진 가장 가치가 높은 디자인을 활용하고, 나머지 10%의 경우에는 무작위로 디자인을 탐색한다.

입실론 그리디 전략에서 지수이동평균을 사용하면 행동의 가치를 계산할 때 최근의 보상을 더 큰 비중으로 반영하여, 트렌드나 계절의 변화에 맞는 디자인으로 자동으로 바꿀 수 있다.