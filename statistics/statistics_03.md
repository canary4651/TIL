# statistics_03

- 주피터노트북 : 통계03 파일

## 추정

- 데이터에서 확률을 보는 것

## 복습

- 분포의 특성을 조절하는 값 → 파라미터
- 그래프 모형
- 선형 모형/ 로지스틱 선형 모형

## 이항분포

- a를 할 때 b일 확률이 p이면
- a를 n번 했을 때 b가 x번 발생할 확률 분포

내가 아침에 간식을 먹을 확률이 80%이면 

내가  데잇걸즈에 30번 왔을 때, 간식을 먹을 때가 x번 발생할까? 

### 최적화를 이용한 파라미터 추정

- 최적화 : 제약조건 아래서 목표 함수를 최대화(최소화) 하는 것
- 파라미터 추정 : 분포/모형의 파라미터를 추정하는 것
- 목표함수 → j 라는 함수가 있다고 생각.
- L = J(p) , 오차(파라미터) → 최소화 시켜야 좋음
- 0 ≤ p ≤ 1

### 평균 오차 제곱

- 연속변수를 예측할 때 사용
- 오차 = 예측과 실제의 차이 (y - y')제곱
- 평균 오차 제곱(MSE)이 최소화되도록 파라미터를 추정
- 제곱을 하는 이유? → - 값이 나올 수도 있으니까!
- 모든 예측을 평균으로 하면 MSE는 분산과 같아짐
- 경사하강법

## 우도 likelihood → 있을법함, 그럴듯함

- 모형과 파라미터를 가정 했을 때 현재 데이터 D가 관찰될 확률
- 오차로 접근하는 게 아니라 확률로 접근
- P(D|M) # 데이터 → 파라미터/ 파라미터 → 데이터
- 최대우도법(Maximum Likelihood): 우도를 최대로 하는 파라미터를 찾는 방법 (ML)
- 우도는 확률 중에서도 특정한 경우
- 우도 : 파라미터를 가정했을 때 데이터가 관찰될 확률 (조건부확률) → 파라미터가 조건이 되는 거

## 확률 질량 함수 : probability mass function

- 이산 확률 변수에서 특정 값의 확률을 나타내는 함수
- 파라미터 rvs 데이터
- 파라미터 데이터 pmf 확률
- data가 있을 때 p를 구하고 싶음.(확률) 그러니까 이걸 우도라고 하고, 조건을 바꿔서 넣을때(파라미터) 확률(우도)를 최대로 해서 찾아보자. 정확하게 같지는 않지만 터무니없게 다르지는 않음

### 로그 우도

- 많은 우도를 곱할 경우 계산이 까다로움
- 우도 대신 로그 우도를 사용하면 곱셈 대신 덧셈을 사용할 수 있음
- log (𝑎 × 𝑏) = log(𝑎) + log (b)
- 데이터 → 로그 우도 : x 대신에 + 를 하기 위해서  | 파라미터 (a,b,c ...) → mse최소
- 파라미터 (a,b,c ...) → mse최소
- 파라미터(p) → 최대 우도

## 선형 모형/ 로지스틱모형

- 선형모형: y = ax + b : y 범위가 무한대  → 최소 mse 추정
- 로지스틱 모형: y = expit(ax+b) : 범위가 0-1 정해져있음 (0<y<1) → 최대우도 추정

## 배워서 어디에 써먹는걸까?

- 모든 관계를 그림으로 나타낼 수 있음. 0 → 0 요런 그림!
- 실제 데이터분석할 땐 이미 식이 존재합니당! 우린 지금 원리부터 보고 있는 거임~~
- 결국 예측을 하기 위해 쓰는 거

### 실제 데이터 셋

[https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)

- automobile
- imports-85.data 파일