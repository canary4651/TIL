{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 (valid는 20% uniform random sampling)\n",
    "metadata = pd.read_csv('metadata.csv')\n",
    "ratings_train = pd.read_csv('ratings-train.csv')\n",
    "ratings_valid = pd.read_csv('ratings-valid.csv').sample(frac=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def rmse(expected, answer):\n",
    "    merged = pd.merge(answer, expected, on=['userid', 'itemid'], how='left')\n",
    "    merged['rating_y'] = merged['rating_y'].fillna(0)\n",
    "    merged['square_error'] = (merged['rating_x'] - merged['rating_y']) ** 2\n",
    "    return merged['square_error'].mean() ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaccard similarity\n",
    "# u, v => len(i_dict[u] & i_dict[v]) / len(i_dict[u] | i_dict[v])\n",
    "all_users = ratings_train['userid'].unique()\n",
    "i_dict = {u: set(ratings_train[ratings_train['userid'] == u]['itemid'])\n",
    "          for u in all_users}\n",
    "def sim(u, v):\n",
    "    i_u = i_dict[u]\n",
    "    i_v = i_dict[v]\n",
    "    \n",
    "    cup = i_dict[u] | i_dict[v]\n",
    "    cap = i_dict[u] & i_dict[v]\n",
    "    \n",
    "    if len(cup) == 0:\n",
    "        return 0.0\n",
    "    return len(cap) / len(cup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08333333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim('TERhUA==', 'Q1ladXM=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_users(u, k):\n",
    "    sims = [(sim(u, v), v) for v in all_users if u != v]\n",
    "    sorted_sims = sorted(sims, reverse=True)\n",
    "    topk_sims = sorted_sims[:k]\n",
    "    topk_users = [v for s, v in topk_sims]\n",
    "    \n",
    "    return pd.DataFrame(topk_users, columns=['userid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YzkyQQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NGdmcVQ=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2hETGQ=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V0NyaQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QTB5d0E=</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userid\n",
       "0  YzkyQQ==\n",
       "1  NGdmcVQ=\n",
       "2  M2hETGQ=\n",
       "3  V0NyaQ==\n",
       "4  QTB5d0E="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_users('TERhUA==', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_mean = ratings_train.groupby('userid')['rating'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.191210568409944"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_mean = ratings_train.groupby('userid')['rating'].mean().reset_index()\n",
    "def predict(u, i):\n",
    "    topk = similar_users(u, 10)\n",
    "    topk['sim'] = topk.apply(lambda x: sim(u, x['userid']), axis=1)\n",
    "    joined = pd.merge(topk, ratings_train[ratings_train['itemid'] == i], on='userid')\n",
    "    joined = pd.merge(joined, r_mean, on='userid')\n",
    "    joined['score'] = joined['sim'] * (joined['rating_x'] - joined['rating_y'])\n",
    "    mean_u = r_mean[r_mean['userid'] == u]['rating'].iloc[0]\n",
    "    sim_sum = joined['sim'].sum()\n",
    "    r_ui = mean_u\n",
    "    if len(joined) > 0:\n",
    "        r_ui += joined['score'].sum() / sim_sum\n",
    "    \n",
    "    return r_ui\n",
    "    \n",
    "expected = ratings_valid.copy()\n",
    "expected['rating'] = expected.apply(\n",
    "    lambda x: predict(x['userid'], x['itemid']), axis=1)\n",
    "\n",
    "rmse(expected, ratings_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprise 라이브러리의 User-User CF 실습해보기 (p. 44)\n",
    "from surprise import Reader, Dataset\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "train_ds = Dataset.load_from_df(ratings_train, reader).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 50\n",
      "Processing epoch 51\n",
      "Processing epoch 52\n",
      "Processing epoch 53\n",
      "Processing epoch 54\n",
      "Processing epoch 55\n",
      "Processing epoch 56\n",
      "Processing epoch 57\n",
      "Processing epoch 58\n",
      "Processing epoch 59\n",
      "Processing epoch 60\n",
      "Processing epoch 61\n",
      "Processing epoch 62\n",
      "Processing epoch 63\n",
      "Processing epoch 64\n",
      "Processing epoch 65\n",
      "Processing epoch 66\n",
      "Processing epoch 67\n",
      "Processing epoch 68\n",
      "Processing epoch 69\n",
      "Processing epoch 70\n",
      "Processing epoch 71\n",
      "Processing epoch 72\n",
      "Processing epoch 73\n",
      "Processing epoch 74\n",
      "Processing epoch 75\n",
      "Processing epoch 76\n",
      "Processing epoch 77\n",
      "Processing epoch 78\n",
      "Processing epoch 79\n",
      "Processing epoch 80\n",
      "Processing epoch 81\n",
      "Processing epoch 82\n",
      "Processing epoch 83\n",
      "Processing epoch 84\n",
      "Processing epoch 85\n",
      "Processing epoch 86\n",
      "Processing epoch 87\n",
      "Processing epoch 88\n",
      "Processing epoch 89\n",
      "Processing epoch 90\n",
      "Processing epoch 91\n",
      "Processing epoch 92\n",
      "Processing epoch 93\n",
      "Processing epoch 94\n",
      "Processing epoch 95\n",
      "Processing epoch 96\n",
      "Processing epoch 97\n",
      "Processing epoch 98\n",
      "Processing epoch 99\n",
      "Processing epoch 100\n",
      "Processing epoch 101\n",
      "Processing epoch 102\n",
      "Processing epoch 103\n",
      "Processing epoch 104\n",
      "Processing epoch 105\n",
      "Processing epoch 106\n",
      "Processing epoch 107\n",
      "Processing epoch 108\n",
      "Processing epoch 109\n",
      "Processing epoch 110\n",
      "Processing epoch 111\n",
      "Processing epoch 112\n",
      "Processing epoch 113\n",
      "Processing epoch 114\n",
      "Processing epoch 115\n",
      "Processing epoch 116\n",
      "Processing epoch 117\n",
      "Processing epoch 118\n",
      "Processing epoch 119\n",
      "Processing epoch 120\n",
      "Processing epoch 121\n",
      "Processing epoch 122\n",
      "Processing epoch 123\n",
      "Processing epoch 124\n",
      "Processing epoch 125\n",
      "Processing epoch 126\n",
      "Processing epoch 127\n",
      "Processing epoch 128\n",
      "Processing epoch 129\n",
      "Processing epoch 130\n",
      "Processing epoch 131\n",
      "Processing epoch 132\n",
      "Processing epoch 133\n",
      "Processing epoch 134\n",
      "Processing epoch 135\n",
      "Processing epoch 136\n",
      "Processing epoch 137\n",
      "Processing epoch 138\n",
      "Processing epoch 139\n",
      "Processing epoch 140\n",
      "Processing epoch 141\n",
      "Processing epoch 142\n",
      "Processing epoch 143\n",
      "Processing epoch 144\n",
      "Processing epoch 145\n",
      "Processing epoch 146\n",
      "Processing epoch 147\n",
      "Processing epoch 148\n",
      "Processing epoch 149\n",
      "Processing epoch 150\n",
      "Processing epoch 151\n",
      "Processing epoch 152\n",
      "Processing epoch 153\n",
      "Processing epoch 154\n",
      "Processing epoch 155\n",
      "Processing epoch 156\n",
      "Processing epoch 157\n",
      "Processing epoch 158\n",
      "Processing epoch 159\n",
      "Processing epoch 160\n",
      "Processing epoch 161\n",
      "Processing epoch 162\n",
      "Processing epoch 163\n",
      "Processing epoch 164\n",
      "Processing epoch 165\n",
      "Processing epoch 166\n",
      "Processing epoch 167\n",
      "Processing epoch 168\n",
      "Processing epoch 169\n",
      "Processing epoch 170\n",
      "Processing epoch 171\n",
      "Processing epoch 172\n",
      "Processing epoch 173\n",
      "Processing epoch 174\n",
      "Processing epoch 175\n",
      "Processing epoch 176\n",
      "Processing epoch 177\n",
      "Processing epoch 178\n",
      "Processing epoch 179\n",
      "Processing epoch 180\n",
      "Processing epoch 181\n",
      "Processing epoch 182\n",
      "Processing epoch 183\n",
      "Processing epoch 184\n",
      "Processing epoch 185\n",
      "Processing epoch 186\n",
      "Processing epoch 187\n",
      "Processing epoch 188\n",
      "Processing epoch 189\n",
      "Processing epoch 190\n",
      "Processing epoch 191\n",
      "Processing epoch 192\n",
      "Processing epoch 193\n",
      "Processing epoch 194\n",
      "Processing epoch 195\n",
      "Processing epoch 196\n",
      "Processing epoch 197\n",
      "Processing epoch 198\n",
      "Processing epoch 199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f531df0eac8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNBasic, KNNWithMeans, SVD\n",
    "\n",
    "model = SVD(random_state=17, n_factors=200, n_epochs=200, lr_all=0.0052, reg_all=0.04,\n",
    "            verbose=True)\n",
    "model.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9359638225728149"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(u, i):\n",
    "    return model.predict(u, i).est\n",
    "\n",
    "expected = ratings_valid.copy()\n",
    "expected['rating'] = expected.apply(\n",
    "    lambda x: predict(x['userid'], x['itemid']), axis=1)\n",
    "\n",
    "rmse(expected, ratings_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5834, 200)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.qi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qi = pd.DataFrame(model.qi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qi.to_csv('qi.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iids = pd.DataFrame([train_ds.to_raw_iid(i) for i in train_ds.all_items()],\n",
    "                       columns=['itemid'])\n",
    "df_titles = pd.merge(df_iids, metadata[['itemid', 'title']], on='itemid', how='inner')\n",
    "df_titles['title'].to_csv('titles.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_custom = pd.read_csv('영화 평가 - 시트1.csv')\n",
    "\n",
    "ratings_custom['dataitgirls'] = 1\n",
    "ratings_train['dataitgirls'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_concat = pd.concat((ratings_custom, ratings_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.load_from_df(\n",
    "    ratings_concat[['userid', 'itemid', 'rating']], reader).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f531dfe7f98>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVD(n_factors=150, n_epochs=100, random_state=17, biased=False)\n",
    "model.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['adela', 'bomin', 'chiwan', 'dahye', 'danbi', 'gilim', 'hansol',\n",
       "        'Heeyawl', 'kwang', 'mihyeon', 'minju', 'Song', 'sunmi', 'wooju',\n",
       "        'yeeun', 'yeseul'], dtype=object), 16)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = ratings_custom['userid'].unique()\n",
    "people, len(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.to_inner_uid('chiwan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu = []\n",
    "names = []\n",
    "for name in people:\n",
    "    names.append(name)\n",
    "    inner_uid = train_ds.to_inner_uid(name)\n",
    "    pu.append(model.pu[inner_uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pu = pd.DataFrame(pu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = pd.DataFrame(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pu.to_csv('pu.tsv', sep='\\t', index=False, header=False)\n",
    "df_names.to_csv('names.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv-ds)",
   "language": "python",
   "name": "venv-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
